{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() # this must be executed before the below import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Python Spark SQL Execution\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\",\"8g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\",True) \\\n",
    "    .config(\"spark.memory.offHeap.size\",\"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# none of these can affect \"second time faster\"\n",
    "# .config(\"spark.sql.optimizer.metadataOnly\", False)\n",
    "# .config(\"spark.shuffle.service.index.cache.size\", \"0m\")\n",
    "# .config(\"spark.files.useFetchCache\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import rtree\n",
    "from rtree import index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from NORAPartitionTree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_overlap_parquets(query, partition_index):\n",
    "    '''\n",
    "    find out all the overlap partition ids\n",
    "    '''\n",
    "    query_lower = [qr[0] for qr in query]\n",
    "    query_upper = [qr[1] for qr in query]\n",
    "    query_border = tuple(query_lower + query_upper)\n",
    "    overlap_pids = list(partition_index.intersection(query_border))\n",
    "    \n",
    "    return overlap_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transform_query_to_sql(query, used_dims, column_name_dict, hdfs_path, querytype = 0, pids = None):\n",
    "    sql = ''\n",
    "    for i, dim in enumerate(used_dims):\n",
    "        #if query[i][0] != -1:\n",
    "        sql += column_name_dict[dim] + '>' + str(query[i]) + ' and '\n",
    "        #if query[i][1] != -1:\n",
    "        sql += column_name_dict[dim] + '<' + str(query[len(used_dims)+i]) + ' and '\n",
    "    sql = sql[0:-4] # remove the last 'and '\n",
    "    print(\"pids:\",pids)\n",
    "    if pids is not None and len(pids) != 0:\n",
    "        pids = str(set(pids)).replace(\" \", \"\") # '{1,2,3}'\n",
    "        hdfs_path = hdfs_path + '/partition_' + pids + \".parquet\"\n",
    "    \n",
    "    if querytype == 0:\n",
    "        sql = \"SELECT * FROM parquet.`\" + hdfs_path + \"`WHERE \" + sql\n",
    "    elif querytype == 1:\n",
    "        sql = \"SELECT COUNT(*) FROM parquet.`\" + hdfs_path + \"`WHERE \" + sql\n",
    "    elif querytype == 2:\n",
    "        sql = \"SELECT variance(_c0) FROM parquet.`\" + hdfs_path + \"`WHERE \" + sql\n",
    "            \n",
    "    #else:\n",
    "        #pids = str(set(pids)).replace(\" \", \"\") # '{1,2,3}'\n",
    "        #sql = \"SELECT * FROM parquet.`\" + hdfs_path + 'partition_' + pids + \".parquet` WHERE \" + sql\n",
    "        #sql = \"SELECT COUNT(*) FROM parquet.`\" + hdfs_path + 'partition_' + pids + \".parquet` WHERE \" + sql\n",
    "        #sql = \"SELECT variance(_c0) FROM parquet.`\" + hdfs_path + 'partition_' + pids + \".parquet` WHERE \" + sql\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def query_with_parquets(query, used_dims, column_name_dict, hdfs_path, querytype = 0, partition_tree = None, print_execution_time = False):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sql = None    \n",
    "    \n",
    "    if partition_tree == None:\n",
    "        sql = transform_query_to_sql(query, used_dims, column_name_dict, hdfs_path, querytype)\n",
    "    else:\n",
    "        pids = partition_tree.query_single(query) # find_overlap_parquets(query, rtree_idx)\n",
    "        sql = transform_query_to_sql(query, used_dims, column_name_dict, hdfs_path, querytype, pids)\n",
    "        #print(sql)\n",
    "    \n",
    "    #print(\"generated sql:\", sql)\n",
    "    end_time_1 = time.time()\n",
    "    \n",
    "    query_result = spark.sql(sql).collect()\n",
    "#     query_result = spark.sql(sql) # lazy execution\n",
    "#     query_time = spark.time(spark.sql(sql).collect())  # there is no .time in pyspark\n",
    "    \n",
    "    end_time_2 = time.time()\n",
    "    \n",
    "#     print(\"result size:\", len(query_result))\n",
    "#     print(\"result content:\", query_result)\n",
    "    \n",
    "    query_translation_time = end_time_1 - start_time\n",
    "    query_execution_time = end_time_2 - end_time_1\n",
    "    #print('query execution time: ', query_execution_time)\n",
    "    \n",
    "    if print_execution_time:\n",
    "        print('query translation time: ', query_translation_time)\n",
    "        print('query execution time: ', query_execution_time)\n",
    "    \n",
    "    #return (query_result, query_translation_time, query_execution_time) # this takes too much memory\n",
    "    return (query_translation_time, query_execution_time, len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_query(path):\n",
    "    query_set = np.genfromtxt(path, delimiter=' ')\n",
    "    #query_set = query_set.reshape(len(query_set),-1,2)\n",
    "    return query_set\n",
    "\n",
    "def kdnode_2_border(kdnode):\n",
    "    lower = [domain[0] for domain in kdnode[0]]\n",
    "    upper = [domain[1] for domain in kdnode[0]]\n",
    "    border = tuple(lower + upper) # non interleave\n",
    "    return border\n",
    "\n",
    "def load_partitions_from_file(path):\n",
    "    '''\n",
    "    the loaded stretched_kdnodes: [num_dims, l1,l2,...,ln, u1,u2,...,un, size, id, pid, left_child,id, right_child_id]\n",
    "    '''\n",
    "    stretched_kdnodes = np.genfromtxt(path, delimiter=',')\n",
    "    num_dims = int(stretched_kdnodes[0,0])\n",
    "    kdnodes = []\n",
    "    for i in range(len(stretched_kdnodes)):\n",
    "        domains = [ [stretched_kdnodes[i,k+1],stretched_kdnodes[i,1+num_dims+k]] for k in range(num_dims) ]\n",
    "        row = [domains]\n",
    "        row.append(stretched_kdnodes[i,2*num_dims+1])\n",
    "        # to be compatible with qd-tree's partition, that do not have the last 4 attributes\n",
    "        if len(stretched_kdnodes[i]) > 2*num_dims+2:\n",
    "            row.append(stretched_kdnodes[i,-4])\n",
    "            row.append(stretched_kdnodes[i,-3])\n",
    "            row.append(stretched_kdnodes[i,-2])\n",
    "            row.append(stretched_kdnodes[i,-1])\n",
    "        kdnodes.append(row)\n",
    "    return kdnodes\n",
    "\n",
    "# def prepare_partition_index(partition_path):\n",
    "#     partitions = load_partitions_from_file(partition_path)\n",
    "\n",
    "#     p = index.Property()\n",
    "#     p.leaf_capacity = 32\n",
    "#     p.index_capacity = 32\n",
    "#     p.NearMinimumOverlaoFactor = 16\n",
    "#     p.fill_factor = 0.8\n",
    "#     p.overwrite = True\n",
    "#     pidx = index.Index(properties = p)\n",
    "\n",
    "#     partition_index = index.Index(properties = p)\n",
    "#     for i in range(len(partitions)):\n",
    "#         partition_index.insert(i, kdnode_2_border(partitions[i]))\n",
    "    \n",
    "#     return partition_index\n",
    "\n",
    "def batch_query(queryset, used_dims, column_name_dict, hdfs_path, querytype = 0, partition_path = \"\"):\n",
    "    \n",
    "#     rtree_idx = None\n",
    "#     if use_rtree_idx:\n",
    "#         rtree_idx = prepare_partition_index(partition_path)\n",
    "    \n",
    "    partition_tree = PartitionTree(len(used_dims)) # newly added\n",
    "    partition_tree.load_tree(partition_path)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # add statistics result\n",
    "    results = []\n",
    "    count = 0\n",
    "    for i in range(0, len(queryset)):\n",
    "        result = query_with_parquets(queryset[i], used_dims, column_name_dict, hdfs_path, querytype, partition_tree)\n",
    "        print('finish query', count)\n",
    "        count += 1\n",
    "        results.append(result)\n",
    "        #print(\"query:\",queryset[i])\n",
    "#         if i == 0:\n",
    "#             break # just analysis top k queries\n",
    "    end_time = time.time()\n",
    "    \n",
    "    result_size = 0\n",
    "    for result in results:\n",
    "        result_size += result[2]\n",
    "    avg_result_size = int(result_size // len(queryset))\n",
    "    \n",
    "    print('total query response time: ', end_time - start_time)\n",
    "    print('average query response time: ', (end_time - start_time) / len(queryset))\n",
    "    print('average result size: ', avg_result_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # = = = Configuration (COMP Cloud Ubuntu) = = =\n",
    "\n",
    "# scale_factor = 100\n",
    "# # query_base_path = '/home/cloudray/NORA_Query/'\n",
    "# query_base_path = '/home/ubuntu/Queryset/'\n",
    "\n",
    "# distribution_path = query_base_path + 'distribution_' + str(scale_factor) + '.csv'\n",
    "# random_path = query_base_path + 'random_' + str(scale_factor) + '.csv'\n",
    "\n",
    "# distribution_query = load_query(distribution_path)\n",
    "# random_query = load_query(random_path)\n",
    "\n",
    "# training_set_percentage = 0.5\n",
    "# Td = int(len(distribution_query) * training_set_percentage)\n",
    "# Tr = int(len(random_query) * training_set_percentage)\n",
    "\n",
    "# training_set = np.concatenate((distribution_query[0:Td], random_query[0:Tr]), axis=0)\n",
    "# testing_set = np.concatenate((distribution_query[Td:], random_query[Tr:]), axis=0)\n",
    "\n",
    "# used_dims = [1,2]\n",
    "# num_dims = 16\n",
    "# column_names = ['_c'+str(i) for i in range(num_dims)]\n",
    "# column_name_dict = {}\n",
    "# for i in range(num_dims):\n",
    "#     column_name_dict[i] = column_names[i]\n",
    "\n",
    "# # hdfs_path_nora = 'hdfs://localhost:9000/user/cloudray/NORA/merged/'\n",
    "# # hdfs_path_qdtree = 'hdfs://localhost:9000/user/cloudray/QdTree/merged/'\n",
    "\n",
    "# hdfs_path_nora = 'hdfs://10.88.88.103:9000/user/cloudray/NORA/scale100/merged/'\n",
    "# hdfs_path_qdtree = 'hdfs://10.88.88.103:9000/user/cloudray/QdTree/scale100/merged/'\n",
    "# hdfs_path_kdtree = 'hdfs://10.88.88.103:9000/user/cloudray/KDTree/scale100/merged/'\n",
    "\n",
    "# # partition_base_path = '/home/ubuntu/PartitionLayout/'\n",
    "# # nora_partition = partition_base_path + 'nora_partitions_' + str(scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# = = = Configuration (UBDA Cloud Centos) = = =\n",
    "\n",
    "scale_factor = 10\n",
    "# query_base_path = '/home/centos/Queryset/'\n",
    "\n",
    "# distribution_path = query_base_path + 'distribution_' + str(scale_factor) + '.csv'\n",
    "# random_path = query_base_path + 'random_' + str(scale_factor) + '.csv'\n",
    "\n",
    "# distribution_query = load_query(distribution_path)\n",
    "# random_query = load_query(random_path)\n",
    "\n",
    "# training_set_percentage = 0.5\n",
    "# Td = int(len(distribution_query) * training_set_percentage)\n",
    "# Tr = int(len(random_query) * training_set_percentage)\n",
    "\n",
    "# training_set = np.concatenate((distribution_query[0:Td], random_query[0:Tr]), axis=0)\n",
    "# testing_set = np.concatenate((distribution_query[Td:], random_query[Tr:]), axis=0)\n",
    "\n",
    "problem_type = 2\n",
    "query_path = '/home/centos/Queryset/'\n",
    "# scale 100\n",
    "# training_set = np.genfromtxt(query_path+\"prob\"+str(problem_type)+\"_train.csv\", delimiter=',')\n",
    "# testing_set = np.genfromtxt(query_path+\"prob\"+str(problem_type)+\"_test.csv\", delimiter=',')\n",
    "\n",
    "# scale 50 and 10\n",
    "training_set = np.genfromtxt(query_path+\"prob\"+str(problem_type)+\"_train_scale\"+str(scale_factor)+\".csv\", delimiter=',')\n",
    "testing_set = np.genfromtxt(query_path+\"prob\"+str(problem_type)+\"_test_scale\"+str(scale_factor)+\".csv\", delimiter=',')\n",
    "\n",
    "used_dims = [1,2,3,4]\n",
    "num_dims = 16\n",
    "column_names = ['_c'+str(i) for i in range(num_dims)]\n",
    "column_name_dict = {}\n",
    "for i in range(num_dims):\n",
    "    column_name_dict[i] = column_names[i]\n",
    "\n",
    "# hdfs_path_nora = 'hdfs://localhost:9000/user/cloudray/NORA/merged/'\n",
    "# hdfs_path_qdtree = 'hdfs://localhost:9000/user/cloudray/QdTree/merged/'\n",
    "\n",
    "# scale 100\n",
    "# hdfs_path_nora = 'hdfs://192.168.6.62:9000/user/cloudray/NORA/prob'+str(problem_type)+'/merged/'\n",
    "# hdfs_path_qdtree = 'hdfs://192.168.6.62:9000/user/cloudray/QdTree/prob'+str(problem_type)+'/merged/'\n",
    "# # hdfs_path_kdtree = 'hdfs://192.168.6.62:9000/user/cloudray/KDTree/prob'+str(problem_type)+'/merged/'\n",
    "# hdfs_path_kdtree = 'hdfs://192.168.6.62:9000/user/cloudray/KDTree/prob'+str(1)+'/merged/'\n",
    "\n",
    "# scale 50 and 10\n",
    "hdfs_base_path = 'hdfs://192.168.6.62:9000/user/cloudray/'\n",
    "hdfs_path_nora = hdfs_base_path + 'NORA/prob' + str(problem_type) + '/scale' + str(scale_factor) + \"/merged/\"\n",
    "hdfs_path_qdtree = hdfs_base_path + 'QdTree/prob' + str(problem_type) + '/scale' + str(scale_factor) + \"/merged/\"\n",
    "hdfs_path_kdtree = hdfs_base_path + 'KDTree/prob' + str(problem_type) + '/scale' + str(scale_factor) + \"/merged/\"\n",
    "\n",
    "# hdfs_path_nora = 'hdfs://192.168.6.62:9000/user/cloudray/NORA/scale100/reorganized'\n",
    "# hdfs_path_qdtree = 'hdfs://192.168.6.62:9000/user/cloudray/QdTree/scale100/reorganized'\n",
    "# hdfs_path_kdtree = 'hdfs://192.168.6.62:9000/user/cloudray/KDTree/scale100/reorganized'\n",
    "\n",
    "# newly added\n",
    "querytype = 0 # 0: SELECT *;  2: SELECT variance(_c0)\n",
    "partition_base_path = '/home/centos/PartitionLayout/'\n",
    "\n",
    "# scale 100\n",
    "# nora_partition_path = partition_base_path + 'prob' + str(problem_type) + '_nora'\n",
    "# qdtree_partition_path = partition_base_path + 'prob' + str(problem_type) + '_qdtree'\n",
    "# kdtree_partition_path = partition_base_path + 'prob' + str(problem_type) + '_kdtree'\n",
    "\n",
    "# scale 50 and 10\n",
    "nora_partition_path = partition_base_path + 'prob' + str(problem_type) + '_nora_scale' + str(scale_factor)\n",
    "qdtree_partition_path = partition_base_path + 'prob' + str(problem_type) + '_qdtree_scale' + str(scale_factor)\n",
    "kdtree_partition_path = partition_base_path + 'prob' + str(problem_type) + '_kdtree_scale' + str(scale_factor)\n",
    "\n",
    "# partition_base_path = '/home/ubuntu/PartitionLayout/'\n",
    "# nora_partition = partition_base_path + 'nora_partitions_' + str(scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test query\n",
    "# notice, there should not be any white space between and two pids\n",
    "# sql = 'SELECT * FROM parquet.`hdfs://10.88.88.103:9000/user/cloudray/NORA/scale100/merged/partition_{164,165}.parquet`'\n",
    "# sql = 'SELECT variance(_c0) FROM parquet.`hdfs://10.88.88.103:9000/user/cloudray/NORA/scale100/merged/partition_{164,165}.parquet`'\n",
    "# result = spark.sql(sql).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# len(result) # 0 and 1: 3124568\n",
    "# len(result) # 0: 1556604\n",
    "# len(result) # 1: 1567964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NORA\n",
    "# batch_query(testing_set, used_dims, column_name_dict, hdfs_path_nora, partition_index)\n",
    "\n",
    "# SELECT *\n",
    "# total query response time:  861.4990439414978\n",
    "# average query response time:  17.229980878829956\n",
    "\n",
    "# SELECT COUNT(*) # the advantage is more obvious when io of query result do not dominate the query time\n",
    "# total query response time:  24.595819234848022\n",
    "# average query response time:  0.4919163846969605\n",
    "\n",
    "# SELECT variance(_c0)\n",
    "# total query response time:  32.315288066864014\n",
    "# average query response time:  0.6463057613372802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Qd-Tree\n",
    "# batch_query(testing_set, used_dims, column_name_dict, hdfs_path_qdtree)\n",
    "\n",
    "# SELECT *\n",
    "# total query response time:  1169.1192693710327\n",
    "# average query response time:  23.382385387420655/\n",
    "\n",
    "# SELECT COUNT(*)\n",
    "# total query response time:  85.07339429855347\n",
    "# average query response time:  1.7014678859710692\n",
    "\n",
    "# SELECT variance(_c0)\n",
    "# total query response time:  102.03884530067444\n",
    "# average query response time:  2.040776906013489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# spark.catalog.listDatabases() # [Database(name='default', description='default database', locationUri='file:/home/centos/NORA_SPARK/spark-warehouse')]\n",
    "# spark.catalog.listTables() # []\n",
    "# spark.catalog.listTables('default') # []\n",
    "# spark.catalog.refreshByPath('hdfs://192.168.6.62:9000/user/cloudray/QdTree/scale100/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "# NORA\n",
    "# batch_query(training_set, used_dims, column_name_dict, hdfs_path_nora, querytype, nora_partition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "# Qd-Tree\n",
    "# batch_query(training_set, used_dims, column_name_dict, hdfs_path_qdtree, querytype, qdtree_partition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "# KDTree\n",
    "# batch_query(training_set, used_dims, column_name_dict, hdfs_path_kdtree, querytype, kdtree_partition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pids: [41]\n",
      "finish query 0\n",
      "pids: [41]\n",
      "finish query 1\n",
      "pids: [41]\n",
      "finish query 2\n",
      "pids: [41]\n",
      "finish query 3\n",
      "pids: [52]\n",
      "finish query 4\n",
      "pids: [52]\n",
      "finish query 5\n",
      "pids: [52]\n",
      "finish query 6\n",
      "pids: [52]\n",
      "finish query 7\n",
      "pids: [26]\n",
      "finish query 8\n",
      "pids: [26]\n",
      "finish query 9\n",
      "pids: [26]\n",
      "finish query 10\n",
      "pids: [26]\n",
      "finish query 11\n",
      "pids: [26]\n",
      "finish query 12\n",
      "pids: [15]\n",
      "finish query 13\n",
      "pids: [15]\n",
      "finish query 14\n",
      "pids: [15]\n",
      "finish query 15\n",
      "pids: [15]\n",
      "finish query 16\n",
      "pids: [16]\n",
      "finish query 17\n",
      "pids: [49]\n",
      "finish query 18\n",
      "pids: [49]\n",
      "finish query 19\n",
      "pids: [49]\n",
      "finish query 20\n",
      "pids: [37]\n",
      "finish query 21\n",
      "pids: [37]\n",
      "finish query 22\n",
      "pids: [37]\n",
      "finish query 23\n",
      "pids: [37]\n",
      "finish query 24\n",
      "pids: [37]\n",
      "finish query 25\n",
      "pids: [31]\n",
      "finish query 26\n",
      "pids: [31]\n",
      "finish query 27\n",
      "pids: [38]\n",
      "finish query 28\n",
      "pids: [38]\n",
      "finish query 29\n",
      "pids: [38]\n",
      "finish query 30\n",
      "pids: [38]\n",
      "finish query 31\n",
      "pids: [42]\n",
      "finish query 32\n",
      "pids: [42]\n",
      "finish query 33\n",
      "pids: [48]\n",
      "finish query 34\n",
      "pids: [48]\n",
      "finish query 35\n",
      "pids: [48]\n",
      "finish query 36\n",
      "pids: [48]\n",
      "finish query 37\n",
      "pids: [50]\n",
      "finish query 38\n",
      "pids: [50]\n",
      "finish query 39\n",
      "pids: [31]\n",
      "finish query 40\n",
      "pids: [31]\n",
      "finish query 41\n",
      "pids: [31]\n",
      "finish query 42\n",
      "pids: [31]\n",
      "finish query 43\n",
      "pids: [52]\n",
      "finish query 44\n",
      "pids: [34, 56]\n",
      "finish query 45\n",
      "pids: [26]\n",
      "finish query 46\n",
      "pids: [26]\n",
      "finish query 47\n",
      "pids: [26]\n",
      "finish query 48\n",
      "pids: [26]\n",
      "finish query 49\n",
      "pids: [26]\n",
      "finish query 50\n",
      "pids: [33, 49]\n",
      "finish query 51\n",
      "pids: [33, 49]\n",
      "finish query 52\n",
      "pids: [33, 49]\n",
      "finish query 53\n",
      "pids: [33, 49]\n",
      "finish query 54\n",
      "pids: [45]\n",
      "finish query 55\n",
      "pids: [45]\n",
      "finish query 56\n",
      "pids: [50]\n",
      "finish query 57\n",
      "pids: [50]\n",
      "finish query 58\n",
      "pids: [50]\n",
      "finish query 59\n",
      "pids: [50]\n",
      "finish query 60\n",
      "pids: [50]\n",
      "finish query 61\n",
      "pids: [32]\n",
      "finish query 62\n",
      "pids: [32]\n",
      "finish query 63\n",
      "pids: [25]\n",
      "finish query 64\n",
      "pids: [25]\n",
      "finish query 65\n",
      "pids: [25]\n",
      "finish query 66\n",
      "pids: [35]\n",
      "finish query 67\n",
      "pids: [25]\n",
      "finish query 68\n",
      "pids: [45]\n",
      "finish query 69\n",
      "pids: [45]\n",
      "finish query 70\n",
      "pids: [45]\n",
      "finish query 71\n",
      "pids: [45]\n",
      "finish query 72\n",
      "pids: [25]\n",
      "finish query 73\n",
      "pids: [25]\n",
      "finish query 74\n",
      "pids: [25]\n",
      "finish query 75\n",
      "pids: [25]\n",
      "finish query 76\n",
      "pids: [53]\n",
      "finish query 77\n",
      "pids: [53]\n",
      "finish query 78\n",
      "pids: [26]\n",
      "finish query 79\n",
      "pids: [49]\n",
      "finish query 80\n",
      "pids: [49]\n",
      "finish query 81\n",
      "pids: [49]\n",
      "finish query 82\n",
      "pids: [49]\n",
      "finish query 83\n",
      "pids: [39]\n",
      "finish query 84\n",
      "pids: [39]\n",
      "finish query 85\n",
      "pids: [39]\n",
      "finish query 86\n",
      "pids: [26]\n",
      "finish query 87\n",
      "pids: [26]\n",
      "finish query 88\n",
      "pids: [26]\n",
      "finish query 89\n",
      "pids: [47]\n",
      "finish query 90\n",
      "pids: [26]\n",
      "finish query 91\n",
      "pids: [26]\n",
      "finish query 92\n",
      "pids: [26]\n",
      "finish query 93\n",
      "pids: [26]\n",
      "finish query 94\n",
      "pids: [26]\n",
      "finish query 95\n",
      "pids: [26]\n",
      "finish query 96\n",
      "pids: [26]\n",
      "finish query 97\n",
      "pids: [26]\n",
      "finish query 98\n",
      "pids: [55]\n",
      "finish query 99\n",
      "pids: [26]\n",
      "finish query 100\n",
      "pids: [26]\n",
      "finish query 101\n",
      "pids: [26]\n",
      "finish query 102\n",
      "pids: [31]\n",
      "finish query 103\n",
      "pids: [31]\n",
      "finish query 104\n",
      "pids: [31]\n",
      "finish query 105\n",
      "pids: [51]\n",
      "finish query 106\n",
      "pids: [51]\n",
      "finish query 107\n",
      "pids: [38]\n",
      "finish query 108\n",
      "pids: [38]\n",
      "finish query 109\n",
      "pids: [38]\n",
      "finish query 110\n",
      "pids: [38]\n",
      "finish query 111\n",
      "pids: [38]\n",
      "finish query 112\n",
      "pids: [32]\n",
      "finish query 113\n",
      "pids: [47]\n",
      "finish query 114\n",
      "pids: [47]\n",
      "finish query 115\n",
      "pids: [45]\n",
      "finish query 116\n",
      "pids: [45]\n",
      "finish query 117\n",
      "pids: [45]\n",
      "finish query 118\n",
      "pids: [45]\n",
      "finish query 119\n",
      "total query response time:  36.97600436210632\n",
      "average query response time:  0.30813336968421934\n",
      "average result size:  322\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "# NORA\n",
    "batch_query(testing_set, used_dims, column_name_dict, hdfs_path_nora, querytype, nora_partition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pids: [55, 56, 40]\n",
      "finish query 0\n",
      "pids: [55, 56, 40]\n",
      "finish query 1\n",
      "pids: [55, 56, 40]\n",
      "finish query 2\n",
      "pids: [55, 56, 40]\n",
      "finish query 3\n",
      "pids: [47, 48]\n",
      "finish query 4\n",
      "pids: [47, 48]\n",
      "finish query 5\n",
      "pids: [47, 48]\n",
      "finish query 6\n",
      "pids: [47, 48]\n",
      "finish query 7\n",
      "pids: [33, 18, 38, 25]\n",
      "finish query 8\n",
      "pids: [33, 18, 38, 25]\n",
      "finish query 9\n",
      "pids: [33, 18, 38, 25]\n",
      "finish query 10\n",
      "pids: [33, 18, 38, 25]\n",
      "finish query 11\n",
      "pids: [33, 18, 38, 25]\n",
      "finish query 12\n",
      "pids: [15, 53, 54]\n",
      "finish query 13\n",
      "pids: [15, 53, 54]\n",
      "finish query 14\n",
      "pids: [15, 53, 54]\n",
      "finish query 15\n",
      "pids: [15, 53, 54]\n",
      "finish query 16\n",
      "pids: [54, 32]\n",
      "finish query 17\n",
      "pids: [45, 46]\n",
      "finish query 18\n",
      "pids: [45, 46]\n",
      "finish query 19\n",
      "pids: [45, 46]\n",
      "finish query 20\n",
      "pids: [15, 35]\n",
      "finish query 21\n",
      "pids: [15, 35]\n",
      "finish query 22\n",
      "pids: [15, 35]\n",
      "finish query 23\n",
      "pids: [35]\n",
      "finish query 24\n",
      "pids: [35]\n",
      "finish query 25\n",
      "pids: [30]\n",
      "finish query 26\n",
      "pids: [30]\n",
      "finish query 27\n",
      "pids: [36]\n",
      "finish query 28\n",
      "pids: [36]\n",
      "finish query 29\n",
      "pids: [36]\n",
      "finish query 30\n",
      "pids: [36]\n",
      "finish query 31\n",
      "pids: [55, 56]\n",
      "finish query 32\n",
      "pids: [55, 56]\n",
      "finish query 33\n",
      "pids: [45]\n",
      "finish query 34\n",
      "pids: [45]\n",
      "finish query 35\n",
      "pids: [45]\n",
      "finish query 36\n",
      "pids: [45]\n",
      "finish query 37\n",
      "pids: [30]\n",
      "finish query 38\n",
      "pids: [30]\n",
      "finish query 39\n",
      "pids: [30]\n",
      "finish query 40\n",
      "pids: [50, 52]\n",
      "finish query 41\n",
      "pids: [50, 52]\n",
      "finish query 42\n",
      "pids: [50, 52]\n",
      "finish query 43\n",
      "pids: [49, 50]\n",
      "finish query 44\n",
      "pids: [18, 48]\n",
      "finish query 45\n",
      "pids: [25, 51]\n",
      "finish query 46\n",
      "pids: [25, 51, 30]\n",
      "finish query 47\n",
      "pids: [25, 51, 30]\n",
      "finish query 48\n",
      "pids: [25, 51, 30]\n",
      "finish query 49\n",
      "pids: [25]\n",
      "finish query 50\n",
      "pids: [34, 18, 46]\n",
      "finish query 51\n",
      "pids: [34, 18, 46]\n",
      "finish query 52\n",
      "pids: [34, 18, 46]\n",
      "finish query 53\n",
      "pids: [34, 18, 46]\n",
      "finish query 54\n",
      "pids: [41, 42]\n",
      "finish query 55\n",
      "pids: [41, 42]\n",
      "finish query 56\n",
      "pids: [49]\n",
      "finish query 57\n",
      "pids: [49]\n",
      "finish query 58\n",
      "pids: [49]\n",
      "finish query 59\n",
      "pids: [49]\n",
      "finish query 60\n",
      "pids: [49, 50]\n",
      "finish query 61\n",
      "pids: [15, 33]\n",
      "finish query 62\n",
      "pids: [15, 33]\n",
      "finish query 63\n",
      "pids: [24]\n",
      "finish query 64\n",
      "pids: [24]\n",
      "finish query 65\n",
      "pids: [24]\n",
      "finish query 66\n",
      "pids: [18]\n",
      "finish query 67\n",
      "pids: [44, 24]\n",
      "finish query 68\n",
      "pids: [42]\n",
      "finish query 69\n",
      "pids: [42]\n",
      "finish query 70\n",
      "pids: [42]\n",
      "finish query 71\n",
      "pids: [42]\n",
      "finish query 72\n",
      "pids: [24]\n",
      "finish query 73\n",
      "pids: [24]\n",
      "finish query 74\n",
      "pids: [24]\n",
      "finish query 75\n",
      "pids: [24]\n",
      "finish query 76\n",
      "pids: [30]\n",
      "finish query 77\n",
      "pids: [30]\n",
      "finish query 78\n",
      "pids: [25]\n",
      "finish query 79\n",
      "pids: [43, 44, 46]\n",
      "finish query 80\n",
      "pids: [43, 46]\n",
      "finish query 81\n",
      "pids: [43, 46]\n",
      "finish query 82\n",
      "pids: [43, 46]\n",
      "finish query 83\n",
      "pids: [15, 37]\n",
      "finish query 84\n",
      "pids: [15, 37]\n",
      "finish query 85\n",
      "pids: [15, 37]\n",
      "finish query 86\n",
      "pids: [25, 47]\n",
      "finish query 87\n",
      "pids: [25, 47]\n",
      "finish query 88\n",
      "pids: [25, 47]\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "# Qd-Tree\n",
    "batch_query(testing_set, used_dims, column_name_dict, hdfs_path_qdtree, querytype, qdtree_partition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pids: [50]\n",
      "finish query 0\n",
      "pids: [50]\n",
      "finish query 1\n",
      "pids: [50]\n",
      "finish query 2\n",
      "pids: [50]\n",
      "finish query 3\n",
      "pids: [79]\n",
      "finish query 4\n",
      "pids: [79]\n",
      "finish query 5\n",
      "pids: [79]\n",
      "finish query 6\n",
      "pids: [79]\n",
      "finish query 7\n",
      "pids: [56]\n",
      "finish query 8\n",
      "pids: [56]\n",
      "finish query 9\n",
      "pids: [56]\n",
      "finish query 10\n",
      "pids: [56]\n",
      "finish query 11\n",
      "pids: [56]\n",
      "finish query 12\n",
      "pids: [12, 49]\n",
      "finish query 13\n",
      "pids: [12, 49]\n",
      "finish query 14\n",
      "pids: [12, 49]\n",
      "finish query 15\n",
      "pids: [12, 49]\n",
      "finish query 16\n",
      "pids: [11]\n",
      "finish query 17\n",
      "pids: [64]\n",
      "finish query 18\n",
      "pids: [64]\n",
      "finish query 19\n",
      "pids: [64]\n",
      "finish query 20\n",
      "pids: [69]\n",
      "finish query 21\n",
      "pids: [69]\n",
      "finish query 22\n",
      "pids: [69]\n",
      "finish query 23\n",
      "pids: [69]\n",
      "finish query 24\n",
      "pids: [69]\n",
      "finish query 25\n",
      "pids: [83]\n",
      "finish query 26\n",
      "pids: [83]\n",
      "finish query 27\n",
      "pids: [70]\n",
      "finish query 28\n",
      "pids: [70]\n",
      "finish query 29\n",
      "pids: [70]\n",
      "finish query 30\n",
      "pids: [70]\n",
      "finish query 31\n",
      "pids: [49, 50]\n",
      "finish query 32\n",
      "pids: [49, 50]\n",
      "finish query 33\n",
      "pids: [56, 58]\n",
      "finish query 34\n",
      "pids: [56, 58]\n",
      "finish query 35\n",
      "pids: [56, 58]\n",
      "finish query 36\n",
      "pids: [56, 58]\n",
      "finish query 37\n",
      "pids: [34]\n",
      "finish query 38\n",
      "pids: [34]\n",
      "finish query 39\n",
      "pids: [85, 86]\n",
      "finish query 40\n",
      "pids: [38]\n",
      "finish query 41\n",
      "pids: [38]\n",
      "finish query 42\n",
      "pids: [38]\n",
      "finish query 43\n",
      "pids: [80]\n",
      "finish query 44\n",
      "pids: [12, 22, 30, 39, 49, 62, 71, 83]\n",
      "finish query 45\n",
      "pids: [16]\n",
      "finish query 46\n",
      "pids: [16]\n",
      "finish query 47\n",
      "pids: [16]\n",
      "finish query 48\n",
      "pids: [16]\n",
      "finish query 49\n",
      "pids: [16]\n",
      "finish query 50\n",
      "pids: [11, 12, 20, 22]\n",
      "finish query 51\n",
      "pids: [11, 12, 20, 22]\n",
      "finish query 52\n",
      "pids: [11, 12, 20, 22]\n",
      "finish query 53\n",
      "pids: [11, 12, 20, 22]\n",
      "finish query 54\n",
      "pids: [50, 64, 72, 85]\n",
      "finish query 55\n",
      "pids: [50, 64, 72, 85]\n",
      "finish query 56\n",
      "pids: [33]\n",
      "finish query 57\n",
      "pids: [33]\n",
      "finish query 58\n",
      "pids: [33]\n",
      "finish query 59\n",
      "pids: [33]\n",
      "finish query 60\n",
      "pids: [33]\n",
      "finish query 61\n",
      "pids: [9]\n",
      "finish query 62\n",
      "pids: [9]\n",
      "finish query 63\n",
      "pids: [15]\n",
      "finish query 64\n",
      "pids: [15]\n",
      "finish query 65\n",
      "pids: [15]\n",
      "finish query 66\n",
      "pids: [69, 78]\n",
      "finish query 67\n",
      "pids: [61]\n",
      "finish query 68\n",
      "pids: [72]\n",
      "finish query 69\n",
      "pids: [72]\n",
      "finish query 70\n",
      "pids: [72]\n",
      "finish query 71\n",
      "pids: [72]\n",
      "finish query 72\n",
      "pids: [61, 63]\n",
      "finish query 73\n",
      "pids: [61, 63]\n",
      "finish query 74\n",
      "pids: [61, 63]\n",
      "finish query 75\n",
      "pids: [61, 63]\n",
      "finish query 76\n",
      "pids: [77, 78]\n",
      "finish query 77\n",
      "pids: [77]\n",
      "finish query 78\n",
      "pids: [15]\n",
      "finish query 79\n",
      "pids: [22, 62]\n",
      "finish query 80\n",
      "pids: [22, 62]\n",
      "finish query 81\n",
      "pids: [22, 62]\n",
      "finish query 82\n",
      "pids: [22, 62]\n",
      "finish query 83\n",
      "pids: [47]\n",
      "finish query 84\n",
      "pids: [47]\n",
      "finish query 85\n",
      "pids: [47]\n",
      "finish query 86\n",
      "pids: [58]\n",
      "finish query 87\n",
      "pids: [58]\n",
      "finish query 88\n",
      "pids: [58]\n",
      "finish query 89\n",
      "pids: [57]\n",
      "finish query 90\n",
      "pids: [58]\n",
      "finish query 91\n",
      "pids: [56]\n",
      "finish query 92\n",
      "pids: [56]\n",
      "finish query 93\n",
      "pids: [56]\n",
      "finish query 94\n",
      "pids: [56]\n",
      "finish query 95\n",
      "pids: [56]\n",
      "finish query 96\n",
      "pids: [15]\n",
      "finish query 97\n",
      "pids: [15]\n",
      "finish query 98\n",
      "pids: [38, 40]\n",
      "finish query 99\n",
      "pids: [15]\n",
      "finish query 100\n",
      "pids: [15, 16]\n",
      "finish query 101\n",
      "pids: [15]\n",
      "finish query 102\n",
      "pids: [86]\n",
      "finish query 103\n",
      "pids: [86]\n",
      "finish query 104\n",
      "pids: [86]\n",
      "finish query 105\n",
      "pids: [33, 34, 37, 38, 39, 40]\n",
      "finish query 106\n",
      "pids: [33, 34, 37, 38, 39, 40]\n",
      "finish query 107\n",
      "pids: [69, 70]\n",
      "finish query 108\n",
      "pids: [69, 70]\n",
      "finish query 109\n",
      "pids: [69, 70]\n",
      "finish query 110\n",
      "pids: [69, 70]\n",
      "finish query 111\n",
      "pids: [69, 70]\n",
      "finish query 112\n",
      "pids: [9]\n",
      "finish query 113\n",
      "pids: [21]\n",
      "finish query 114\n",
      "pids: [21]\n",
      "finish query 115\n",
      "pids: [72]\n",
      "finish query 116\n",
      "pids: [72]\n",
      "finish query 117\n",
      "pids: [72]\n",
      "finish query 118\n",
      "pids: [72]\n",
      "finish query 119\n",
      "total query response time:  76.07332038879395\n",
      "average query response time:  0.6339443365732829\n",
      "average result size:  322\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "# KDTree\n",
    "batch_query(testing_set, used_dims, column_name_dict, hdfs_path_kdtree, querytype, kdtree_partition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check number of row groups\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "# fs = pa.hdfs.connect()\n",
    "fs = pa.fs.HadoopFileSystem('192.168.6.62', port=9000, user='hdfs', replication=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path1 = 'hdfs://192.168.6.62:9000/user/cloudray/NORA/prob1/merged/partition_94.parquet'\n",
    "path2 = 'hdfs://192.168.6.62:9000/user/cloudray/KDTree/prob1/merged/partition_98.parquet'\n",
    "# path1 = 'hdfs://192.168.6.62:9000/user/cloudray/NORA/scale100/partition_99.parquet'             # 51 row groups, serialized_size: 86891\n",
    "# path2 = 'hdfs://192.168.6.62:9000/user/cloudray/NORA/scale100/reorganized/partition_99.parquet'   # 1 rouw group, serialized_size: 7872\n",
    "# path1 = 'hdfs://192.168.6.62:9000/user/cloudray/QdTree/scale100/partition_0.parquet'            # 51 row groups, serialized_size: 90136\n",
    "# path2 = 'hdfs://192.168.6.62:9000/user/cloudray/QdTree/scale100/reorganized/partition_0.parquet'  # 1 rouw group, serialized_size: 9117\n",
    "# path1 = 'hdfs://192.168.6.62:9000/user/cloudray/KDTree/scale100/partition_99.parquet'           # 51 row groups, serialized_size: 86183\n",
    "# path2 = 'hdfs://192.168.6.62:9000/user/cloudray/KDTree/scale100/reorganized/partition_99.parquet' # 1 rouw group, serialized_size: 9053\n",
    "# serialized_size should be the size of footer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarrow._parquet.FileMetaData object at 0x7f14fea08e50>\n",
      "  created_by: parquet-cpp version 1.5.1-SNAPSHOT\n",
      "  num_columns: 16\n",
      "  num_rows: 22730171\n",
      "  num_row_groups: 1\n",
      "  format_version: 1.0\n",
      "  serialized_size: 9138\n",
      "<pyarrow._parquet.RowGroupMetaData object at 0x7f1501b379f0>\n",
      "  num_columns: 16\n",
      "  num_rows: 22730171\n",
      "  total_byte_size: 905159169\n",
      "<pyarrow._parquet.FileMetaData object at 0x7f15010fe720>\n",
      "  created_by: parquet-cpp version 1.5.1-SNAPSHOT\n",
      "  num_columns: 16\n",
      "  num_rows: 1280845\n",
      "  num_row_groups: 1\n",
      "  format_version: 1.0\n",
      "  serialized_size: 9053\n",
      "<pyarrow._parquet.RowGroupMetaData object at 0x7f1500fa19a0>\n",
      "  num_columns: 16\n",
      "  num_rows: 1280845\n",
      "  total_byte_size: 52271062\n"
     ]
    }
   ],
   "source": [
    "fw1 = fs.open_input_file(path1)\n",
    "meta1 = pa.parquet.read_metadata(fw1, memory_map=False)\n",
    "print(meta1)\n",
    "print(meta1.row_group(0))\n",
    "fw1.close()\n",
    "\n",
    "fw2 = fs.open_input_file(path2)\n",
    "meta2 = pa.parquet.read_metadata(fw2, memory_map=False)\n",
    "print(meta2)\n",
    "print(meta2.row_group(0))\n",
    "fw2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}