{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data_helper import DatasetAndQuerysetHelper\n",
    "from partition_algorithm import PartitionAlgorithm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Basic configuration for dataset and block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "used_dims = [1,2,4]\n",
    "dim_nums=len(used_dims)\n",
    "# scale_factor=100\n",
    "# sampling_rate=1/scale_factor\n",
    "# block_size = int(1000000*sampling_rate/10/2)\n",
    "base_path = '/home/liupengju/pycharmProjects/NORA_JOIN_SIMULATION/NORA_experiments'\n",
    "scale_factor=1\n",
    "block_size=10000\n",
    "# expect query amount for table a and b\n",
    "join_a_q_amount=300\n",
    "join_b_q_amount=200\n",
    "join_depth=4\n",
    "join_attr=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generate dataset and queries for table A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "helper = DatasetAndQuerysetHelper(used_dimensions=used_dims, scale_factor=scale_factor)\n",
    "dataset, domains = helper.load_dataset(used_dims)\n",
    "boundary = [interval[0] for interval in domains] + [interval[1] for interval in domains]\n",
    "dim_prob_filter_join = [0 if i==join_attr else 1 for i in range(len(used_dims))]\n",
    "a_training_set, _ = helper.generate_queryset_and_save(join_a_q_amount,dim_prob=dim_prob_filter_join, queryset_type=3)\n",
    "b_training_set, _ = helper.generate_queryset_and_save(join_b_q_amount,dim_prob=dim_prob_filter_join, queryset_type=3)\n",
    "a_training_set_for_join,_=helper.generate_queryset_and_save(join_a_q_amount, queryset_type=3)\n",
    "b_training_set_for_join,_=helper.generate_queryset_and_save(join_b_q_amount, queryset_type=3)\n",
    "# a_training_set,_=helper.generate_queryset_and_save(join_a_q_amount,queryset_type=3)\n",
    "# b_training_set,_=helper.generate_queryset_and_save(join_b_q_amount,queryset_type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper.visualize_queryset_and_dataset(used_dims,a_training_set,dataset=dataset)\n",
    "# helper.visualize_queryset_and_dataset(used_dims,b_training_set,dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Produce join queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def __overlap(q1,q2,dim):\n",
    "    if q1[dim]<=q2[dim]<=q1[dim+dim_nums] or q2[dim]<=q1[dim]<=q2[dim+dim_nums]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 15\n",
      "1 : 10\n",
      "2 : 9\n",
      "3 : 12\n",
      "4 : 22\n",
      "5 : 24\n",
      "6 : 12\n",
      "7 : 13\n",
      "8 : 18\n",
      "9 : 16\n",
      "10 : 25\n",
      "11 : 14\n",
      "12 : 22\n",
      "13 : 17\n",
      "14 : 8\n",
      "15 : 6\n",
      "16 : 9\n",
      "17 : 14\n",
      "18 : 19\n",
      "19 : 13\n",
      "20 : 13\n",
      "21 : 10\n",
      "22 : 21\n",
      "23 : 12\n",
      "24 : 9\n",
      "25 : 20\n",
      "26 : 22\n",
      "27 : 25\n",
      "28 : 9\n",
      "29 : 13\n",
      "30 : 25\n",
      "31 : 10\n",
      "32 : 20\n",
      "33 : 26\n",
      "34 : 27\n",
      "35 : 32\n",
      "36 : 6\n",
      "37 : 16\n",
      "38 : 27\n",
      "39 : 10\n",
      "40 : 10\n",
      "41 : 25\n",
      "42 : 18\n",
      "43 : 11\n",
      "44 : 19\n",
      "45 : 13\n",
      "46 : 8\n",
      "47 : 17\n",
      "48 : 17\n",
      "49 : 10\n"
     ]
    }
   ],
   "source": [
    "#pick join query which will be measure\n",
    "b_join_index=[]\n",
    "for _ in range(50):\n",
    "    b_join_index.append(list(set([random.randint(0,len(b_training_set_for_join)-1) for _ in range(random.randint(1,10))])))\n",
    "# remove block id with overlap join attribute range\n",
    "b_join_queries=[]\n",
    "for ids in b_join_index:\n",
    "    item=[]\n",
    "    for idx in ids:\n",
    "        flag=True\n",
    "        for em in item:\n",
    "            if __overlap(b_training_set_for_join[idx],em,join_attr):\n",
    "                flag=False\n",
    "                break\n",
    "        if flag: item.append(b_training_set_for_join[idx])\n",
    "    b_join_queries.append(item)\n",
    "a_join_queries={}\n",
    "for bid,item in enumerate(b_join_queries):\n",
    "    for qb in item:\n",
    "        a_join_queries[bid]=[]\n",
    "        for qa in a_training_set_for_join:\n",
    "            if __overlap(qa,qb,join_attr):\n",
    "                #remove overlap range queries\n",
    "                flag=True\n",
    "                for qa2 in a_join_queries[bid]:\n",
    "                    # if __overlap(qa2,qa,join_attr):\n",
    "                    if qa2==qa:\n",
    "                        flag=False\n",
    "                        break\n",
    "                if flag: a_join_queries[bid].append(qa)\n",
    "for key in a_join_queries.keys():\n",
    "    print(f\"{key} : {len(a_join_queries[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #pick join query which will be measure\n",
    "# b_join_index=[]\n",
    "# for _ in range(200):\n",
    "#     b_join_index.append(list(set([random.randint(0,len(b_training_set)-1) for _ in range(random.randint(1,10))])))\n",
    "# # remove block id with overlap join attribute range\n",
    "# b_join_queries=[]\n",
    "# for ids in b_join_index:\n",
    "#     item=[]\n",
    "#     for idx in ids:\n",
    "#         flag=True\n",
    "#         for em in item:\n",
    "#             if __overlap(b_training_set[idx],em,join_attr):\n",
    "#                 flag=False\n",
    "#                 break\n",
    "#         if flag: item.append(b_training_set[idx])\n",
    "#     b_join_queries.append(item)\n",
    "# a_join_queries={}\n",
    "# for bid,item in enumerate(b_join_queries):\n",
    "#     for qb in item:\n",
    "#         a_join_queries[bid]=[]\n",
    "#         for qa in a_training_set:\n",
    "#             if __overlap(qa,qb,join_attr):\n",
    "#                 #remove overlap range queries\n",
    "#                 flag=True\n",
    "#                 for qa2 in a_join_queries[bid]:\n",
    "#                     # if __overlap(qa2,qa,join_attr):\n",
    "#                     if qa2==qa:\n",
    "#                         flag=False\n",
    "#                         break\n",
    "#                 if flag: a_join_queries[bid].append(qa)\n",
    "# for key in a_join_queries.keys():\n",
    "#     print(f\"{key} : {len(a_join_queries[key])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Instances for partition algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# My Join Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for cut top join:  11.724139928817749\n",
      "Build Time (s): 31.547045946121216\n",
      "time for cut top join:  7.035642385482788\n",
      "Build Time (s): 21.75641942024231\n"
     ]
    }
   ],
   "source": [
    "#use my join tree base on nora\n",
    "pa_A=PartitionAlgorithm()\n",
    "pa_A.InitializeWithJNORA(a_training_set,len(boundary)//2,boundary,dataset,data_threshold=block_size,join_attr=join_attr,using_kd=True,using_am=False,candidate_size=2,candidate_depth=2,join_depth=join_depth)\n",
    "pa_A.partition_tree.name=\"JNora_A\"\n",
    "\n",
    "pa_B=PartitionAlgorithm()\n",
    "pa_B.InitializeWithJNORA(b_training_set,len(boundary)//2,boundary,dataset,data_threshold=block_size,join_attr=join_attr,using_kd=True,using_am=False,candidate_size=2,candidate_depth=2,join_depth=join_depth)\n",
    "pa_B.partition_tree.name=\"JNora_B\"\n",
    "\n",
    "# Build Time (s): 4.983245611190796\n",
    "# Query cross count: 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Adapt Join Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#use adapt join tree base on nora\n",
    "# pa_A=PartitionAlgorithm()\n",
    "# pa_A.InitializeWithJNORA(a_training_set,len(boundary)//2,boundary,dataset,data_threshold=block_size,join_attr=join_attr,using_kd=True,using_am=True,candidate_size=2,candidate_depth=2,join_depth=join_depth)\n",
    "# pa_A.partition_tree.name=\"JNora_A\"\n",
    "#\n",
    "# pa_B=PartitionAlgorithm()\n",
    "# pa_B.InitializeWithJNORA(b_training_set,len(boundary)//2,boundary,dataset,data_threshold=block_size,join_attr=join_attr,using_kd=True,using_am=True,candidate_size=2,candidate_depth=2,join_depth=join_depth)\n",
    "# pa_B.partition_tree.name=\"JNora_B\"\n",
    "\n",
    "# Build Time (s): 4.138746738433838\n",
    "# Query cross count: 77\n",
    "# Build Time (s): 2.935045003890991\n",
    "# Query cross count: 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get the blocks of co-join query in two tables, depend on join tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2140\n",
      "715\n",
      "107 , 2783737.41\n",
      "214 , 5544905.98\n",
      "[{0: [768, 769, 770, 640, 644, 773, 646, 777, 778, 653, 281, 286, 287, 160, 290, 292, 296, 299, 300, 302, 560, 561, 562, 304, 564, 306, 313, 314, 321, 326, 479, 480, 481, 483, 487, 488, 494, 497, 498, 630, 631, 632, 761, 762, 763, 764, 638, 767]}, {1: [256, 261, 448, 454, 459, 462, 463, 465, 723, 596, 724, 725, 726, 735, 736, 737, 738, 743, 877, 878, 749, 623]}, {2: [256, 575, 576, 449, 579, 580, 581, 582, 711, 712, 593, 595, 468, 469, 615, 616, 617, 621, 622, 623, 255]}, {3: [256, 448, 449, 450, 711, 712, 459, 460, 462, 465, 723, 596, 724, 725, 726, 468, 469, 735, 736, 737, 738, 615, 743, 877, 878, 621, 624, 749, 623, 255]}, {4: [387, 388, 389, 391, 392, 393, 395, 396, 397, 525, 400, 401, 530, 403, 404, 405, 406, 661, 662, 667, 668, 413, 414, 671, 672, 676, 678, 810, 811, 812, 816, 690, 818, 696, 825, 826, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 841, 842, 601, 602, 607, 608, 380]}, {5: [516, 389, 388, 391, 392, 393, 521, 395, 524, 397, 525, 527, 528, 401, 530, 403, 529, 405, 661, 662, 664, 667, 796, 413, 668, 799, 800, 801, 802, 672, 671, 676, 678, 807, 808, 810, 811, 812, 670, 815, 816, 818, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 833, 834, 835, 197, 199, 523, 202, 203, 204, 601, 602, 607, 608, 357, 367, 372, 375, 376, 377, 378, 380]}, {6: [256, 448, 449, 450, 711, 712, 460, 462, 465, 723, 596, 724, 725, 726, 468, 469, 735, 736, 737, 738, 615, 616, 617, 743, 877, 622, 878, 621, 623, 624, 749, 255]}, {7: [256, 261, 283, 300, 302, 448, 454, 459, 462, 463, 465, 723, 596, 724, 725, 726, 735, 736, 481, 737, 738, 743, 877, 878, 749, 623, 625, 754, 626]}, {8: [387, 388, 389, 391, 392, 393, 521, 395, 396, 397, 525, 401, 530, 403, 404, 405, 661, 662, 667, 668, 413, 414, 671, 672, 676, 678, 810, 811, 812, 816, 818, 825, 826, 829, 830, 831, 832, 833, 834, 835, 197, 199, 601, 602, 607, 608, 375, 376, 380]}, {9: [256, 575, 448, 576, 447, 579, 580, 581, 449, 711, 712, 713, 714, 582, 460, 589, 593, 723, 724, 725, 726, 468, 469, 595, 615, 616, 617, 621, 622, 623, 255]}, {10: [512, 513, 516, 389, 518, 519, 520, 521, 524, 525, 781, 655, 656, 785, 786, 787, 788, 661, 662, 782, 664, 529, 795, 796, 667, 668, 799, 800, 801, 802, 670, 805, 806, 807, 808, 811, 812, 815, 816, 818, 821, 822, 823, 824, 825, 197, 199, 202, 203, 204, 348, 527, 528, 357, 359, 360, 361, 366, 367, 370, 372, 375, 376, 377, 378, 891]}, {11: [388, 391, 392, 395, 396, 400, 401, 404, 405, 406, 412, 541, 414, 413, 672, 671, 681, 810, 690, 696, 829, 830, 831, 833, 834, 835, 836, 837, 838, 841, 842, 843, 601, 602, 607, 608]}, {12: [387, 516, 389, 388, 391, 392, 393, 521, 395, 396, 397, 524, 525, 523, 401, 530, 403, 405, 661, 662, 667, 796, 413, 414, 671, 672, 668, 676, 678, 810, 811, 812, 816, 818, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 833, 834, 835, 197, 199, 202, 203, 204, 601, 602, 607, 608, 357, 375, 376, 377, 378, 380]}, {13: [256, 261, 283, 300, 302, 448, 449, 450, 454, 711, 712, 459, 460, 462, 463, 465, 723, 596, 724, 725, 726, 468, 469, 735, 736, 481, 737, 738, 615, 743, 877, 878, 621, 749, 625, 754, 626, 624, 623, 255]}, {14: [736, 737, 738, 256, 261, 454, 743, 877, 878, 749, 623, 465, 462, 463, 596, 735]}, {15: [256, 448, 449, 460, 462, 465, 723, 596, 724, 725, 726, 468, 469, 736, 738, 615, 743, 877, 878, 621, 749, 623]}, {16: [768, 769, 770, 773, 281, 286, 287, 160, 290, 292, 296, 299, 300, 302, 560, 304, 561, 306, 564, 313, 314, 479, 480, 481, 483, 487, 488, 498, 630, 631, 632, 761, 767]}, {17: [256, 261, 448, 449, 454, 711, 712, 459, 460, 462, 463, 465, 723, 596, 724, 725, 726, 468, 469, 735, 736, 737, 738, 615, 743, 877, 878, 621, 749, 623]}, {18: [640, 769, 770, 643, 644, 516, 646, 515, 517, 649, 777, 651, 778, 653, 654, 638, 650, 785, 786, 787, 788, 652, 639, 782, 795, 796, 561, 562, 180, 322, 326, 329, 330, 331, 335, 336, 337, 338, 339, 340, 345, 781, 347, 350, 358, 359, 360, 493, 494, 505, 496, 885, 886, 503, 504, 889, 506, 508, 637, 510, 767]}, {19: [512, 513, 515, 516, 517, 519, 520, 649, 651, 781, 782, 655, 656, 785, 786, 787, 788, 662, 664, 795, 796, 799, 800, 801, 802, 805, 806, 807, 202, 203, 339, 340, 347, 348, 350, 354, 358, 359, 360, 508, 366, 370, 372, 886, 503, 504, 505, 506, 891, 892]}, {20: [256, 261, 283, 300, 302, 448, 454, 459, 462, 463, 465, 723, 596, 724, 725, 726, 735, 736, 481, 737, 738, 743, 877, 878, 749, 623, 625, 754, 626]}, {21: [256, 448, 449, 459, 462, 465, 723, 596, 724, 725, 726, 468, 469, 735, 736, 737, 738, 743, 877, 878, 749, 623]}, {22: [640, 769, 770, 643, 644, 516, 646, 515, 517, 649, 777, 651, 778, 653, 654, 638, 650, 785, 786, 787, 788, 652, 639, 782, 795, 796, 561, 562, 180, 322, 326, 329, 330, 331, 335, 336, 337, 338, 339, 340, 345, 781, 347, 348, 350, 358, 359, 360, 493, 494, 505, 496, 885, 886, 503, 504, 889, 506, 508, 637, 510, 767]}, {23: [768, 769, 770, 773, 281, 286, 287, 160, 290, 292, 296, 299, 300, 302, 560, 304, 561, 306, 564, 313, 314, 479, 480, 481, 483, 487, 488, 498, 630, 631, 632, 761, 767]}, {24: [256, 448, 449, 450, 711, 712, 460, 723, 596, 724, 725, 726, 468, 469, 736, 738, 615, 616, 617, 743, 877, 622, 878, 621, 623, 624, 749, 255]}, {25: [404, 405, 406, 535, 536, 537, 410, 412, 541, 413, 542, 544, 545, 414, 681, 683, 689, 690, 692, 695, 696, 698, 442, 701, 702, 703, 704, 833, 834, 837, 838, 841, 842, 843, 845, 846, 851, 852, 853, 854, 866, 893]}, {26: [512, 513, 515, 516, 517, 518, 519, 520, 649, 651, 524, 781, 782, 655, 656, 785, 786, 787, 788, 661, 662, 527, 664, 528, 795, 796, 667, 799, 800, 801, 802, 805, 806, 807, 808, 815, 816, 197, 202, 203, 204, 339, 340, 347, 348, 350, 354, 357, 358, 359, 360, 361, 365, 366, 505, 508, 370, 506, 372, 886, 503, 504, 377, 378, 891, 892]}, {27: [512, 513, 643, 644, 517, 518, 516, 515, 649, 519, 651, 520, 781, 782, 655, 656, 785, 786, 787, 788, 527, 662, 528, 664, 795, 796, 799, 800, 801, 802, 805, 806, 807, 808, 815, 816, 180, 202, 203, 204, 337, 338, 339, 340, 652, 347, 348, 350, 354, 358, 359, 360, 361, 365, 366, 505, 508, 370, 372, 886, 503, 504, 889, 506, 891, 892, 510]}, {28: [256, 448, 449, 450, 711, 712, 460, 723, 596, 724, 725, 726, 468, 469, 736, 738, 615, 616, 617, 743, 877, 622, 878, 621, 623, 624, 749, 255]}, {29: [256, 261, 283, 300, 302, 448, 454, 459, 462, 463, 465, 723, 596, 724, 725, 726, 735, 736, 481, 737, 738, 743, 877, 878, 749, 623, 625, 754, 626]}, {30: [512, 513, 643, 644, 517, 518, 516, 515, 649, 519, 651, 520, 781, 782, 655, 656, 785, 786, 787, 788, 527, 662, 528, 664, 795, 796, 799, 800, 801, 802, 805, 806, 807, 808, 815, 816, 180, 202, 203, 204, 337, 338, 339, 340, 652, 347, 348, 350, 354, 358, 359, 360, 361, 365, 366, 505, 508, 370, 372, 886, 503, 504, 889, 506, 891, 892, 510]}, {31: [768, 769, 770, 773, 281, 286, 287, 160, 290, 292, 296, 299, 300, 302, 560, 304, 561, 306, 564, 313, 314, 479, 480, 481, 483, 487, 488, 498, 630, 631, 632, 761, 767]}, {32: [256, 447, 448, 449, 450, 579, 580, 581, 582, 711, 712, 713, 714, 459, 460, 589, 462, 593, 465, 723, 596, 724, 725, 726, 468, 469, 595, 576, 735, 736, 737, 738, 615, 616, 617, 743, 877, 622, 878, 621, 623, 624, 749, 255]}, {33: [387, 516, 389, 388, 391, 392, 393, 521, 395, 396, 397, 524, 527, 528, 401, 530, 403, 525, 405, 661, 662, 529, 664, 667, 796, 413, 414, 799, 800, 801, 802, 672, 671, 668, 676, 807, 808, 678, 810, 811, 812, 670, 815, 816, 818, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 833, 834, 835, 197, 199, 523, 202, 203, 204, 601, 602, 607, 608, 357, 367, 372, 375, 376, 377, 378, 380]}, {34: [516, 389, 392, 393, 521, 395, 524, 397, 525, 655, 656, 528, 527, 403, 530, 405, 661, 662, 664, 529, 667, 796, 668, 670, 799, 800, 801, 802, 672, 671, 805, 806, 807, 808, 676, 810, 811, 812, 678, 815, 816, 818, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 833, 835, 197, 199, 523, 202, 203, 204, 602, 348, 608, 357, 361, 366, 367, 372, 375, 376, 377, 378, 380]}, {35: [512, 513, 515, 516, 517, 518, 389, 519, 520, 521, 524, 525, 781, 655, 656, 785, 786, 787, 788, 661, 662, 782, 664, 529, 795, 796, 667, 668, 799, 800, 801, 802, 670, 805, 806, 807, 808, 811, 812, 815, 816, 818, 821, 822, 823, 824, 825, 197, 199, 202, 203, 204, 339, 340, 348, 527, 528, 354, 503, 357, 358, 359, 360, 504, 361, 365, 366, 367, 505, 508, 370, 506, 372, 375, 376, 377, 378, 891, 892]}, {36: [256, 448, 449, 460, 462, 465, 723, 596, 724, 725, 726, 468, 469, 736, 738, 615, 743, 877, 878, 621, 749, 623]}, {37: [640, 769, 770, 643, 644, 646, 649, 638, 651, 777, 778, 654, 653, 650, 785, 652, 639, 786, 561, 562, 180, 321, 322, 326, 329, 330, 331, 335, 336, 337, 338, 339, 345, 347, 350, 493, 494, 496, 885, 886, 504, 889, 506, 637, 510, 767]}, {38: [516, 389, 392, 393, 521, 395, 524, 397, 525, 655, 656, 528, 527, 403, 530, 405, 661, 662, 664, 529, 667, 796, 668, 670, 799, 800, 801, 802, 672, 671, 805, 806, 807, 808, 676, 810, 811, 812, 678, 815, 816, 818, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 833, 835, 197, 199, 523, 202, 203, 204, 602, 348, 608, 357, 361, 366, 367, 372, 375, 376, 377, 378, 380]}, {39: [256, 261, 448, 454, 459, 462, 463, 465, 723, 596, 724, 725, 726, 735, 736, 737, 738, 743, 877, 878, 749, 623]}, {40: [256, 261, 448, 454, 459, 462, 463, 465, 723, 596, 724, 725, 726, 735, 736, 737, 738, 743, 877, 878, 749, 623]}, {41: [512, 513, 643, 644, 517, 518, 646, 516, 649, 515, 651, 519, 653, 654, 655, 656, 785, 786, 787, 788, 781, 662, 782, 664, 528, 795, 796, 799, 800, 801, 802, 805, 806, 807, 180, 520, 202, 203, 331, 204, 337, 338, 339, 340, 652, 345, 347, 348, 527, 350, 354, 358, 359, 360, 365, 366, 505, 508, 370, 372, 885, 886, 503, 504, 889, 506, 891, 892, 510]}, {42: [387, 388, 389, 391, 392, 393, 521, 395, 396, 397, 525, 401, 530, 403, 404, 405, 661, 662, 667, 668, 413, 414, 671, 672, 676, 678, 810, 811, 812, 816, 818, 825, 826, 829, 830, 831, 832, 833, 834, 835, 197, 199, 601, 602, 607, 608, 375, 376, 380]}, {43: [769, 643, 644, 646, 649, 638, 651, 650, 653, 654, 652, 639, 785, 786, 180, 322, 329, 330, 331, 335, 336, 337, 338, 339, 345, 350, 493, 494, 496, 504, 889, 506, 637, 510, 767]}, {44: [256, 575, 448, 576, 447, 579, 580, 581, 450, 711, 712, 713, 714, 582, 460, 589, 593, 723, 596, 724, 725, 726, 449, 468, 469, 595, 736, 738, 615, 616, 617, 743, 877, 622, 878, 621, 623, 624, 749, 255]}, {45: [512, 513, 515, 516, 517, 519, 520, 649, 651, 781, 782, 655, 656, 785, 786, 787, 788, 662, 664, 795, 796, 799, 800, 801, 802, 805, 806, 807, 202, 203, 339, 340, 347, 348, 350, 354, 358, 359, 360, 508, 366, 370, 372, 886, 503, 504, 505, 506, 891, 892]}, {46: [896, 410, 542, 544, 545, 547, 551, 552, 553, 442, 701, 702, 703, 704, 837, 838, 853, 854, 855, 856, 866, 895]}, {47: [256, 261, 283, 300, 302, 448, 449, 450, 454, 711, 712, 459, 460, 462, 463, 465, 723, 596, 724, 725, 726, 468, 469, 735, 736, 481, 737, 738, 615, 743, 877, 878, 621, 749, 625, 754, 626, 624, 623, 255]}, {48: [256, 261, 283, 300, 302, 448, 449, 450, 454, 711, 712, 459, 460, 462, 463, 465, 723, 596, 724, 725, 726, 468, 469, 735, 736, 481, 737, 738, 615, 743, 877, 878, 621, 749, 625, 754, 626, 624, 623, 255]}, {49: [256, 448, 449, 450, 711, 712, 460, 723, 596, 724, 725, 726, 468, 469, 736, 738, 615, 616, 617, 743, 877, 622, 878, 621, 623, 624, 749, 255]}]\n",
      "[{0: [451, 679, 615, 457, 620, 685, 595, 597, 699]}, {1: [800, 324, 133, 519, 681, 297, 298, 759, 687, 528, 760, 862, 535, 536, 761, 762, 701, 413, 799]}, {2: [515, 388, 799, 800, 421, 679, 681, 685, 687, 433, 434, 565, 571, 699, 701, 451, 323, 324, 457, 865, 363, 249]}, {3: [390, 398, 401, 402, 793, 794, 413, 421, 679, 681, 685, 814, 687, 816, 699, 701, 323, 324, 590, 592, 605, 251]}, {4: [485, 486, 712, 714, 207, 208, 499, 500, 509]}, {5: [612, 708, 294, 487, 488, 331, 702, 606]}, {6: [793, 794, 251, 253]}, {7: [793, 794, 799, 800, 290, 422, 681, 819, 820, 693, 324, 839, 329, 733, 734, 735, 736, 747, 748, 749, 750, 251, 253]}, {8: [388, 487, 488, 501, 502, 249]}, {9: [480, 705, 322, 515, 865, 800, 649, 363, 620, 493, 783, 784, 307, 799, 565, 665, 571, 318, 479]}, {10: [768, 767, 290, 679, 680, 681, 682, 685, 686, 687, 688, 819, 820, 315, 316, 829, 830, 700, 705, 323, 324, 479, 480, 234, 493, 383]}, {11: [509, 290, 515, 516, 805, 806, 167, 510, 300, 625, 819, 244, 820, 635, 253, 798]}, {12: [480, 705, 679, 680, 685, 493, 479]}, {13: [541, 535, 549, 550, 455, 297, 298, 555, 556, 536, 244, 727, 728, 253, 413, 542]}, {14: [800, 649, 557]}, {15: [324, 701, 681, 687, 797]}, {16: [865, 515, 329, 681, 363, 687, 337, 693, 701, 606]}, {17: [641, 865, 515, 541, 615, 455, 297, 617, 363, 457, 555, 433, 306, 434, 821, 822, 632, 413, 542]}, {18: [609, 417, 611, 292, 641, 642, 170, 300, 639, 658, 629, 631, 632, 415]}, {19: [773, 653, 654, 668, 284, 672, 674, 679, 680, 685, 433, 434, 312, 857, 859, 604, 610, 360, 373, 374, 380]}, {20: [800, 486, 499, 500, 799]}, {21: [352, 736, 800, 747, 748, 749, 750, 734, 799, 565, 857, 571, 733, 606, 735]}, {22: [610, 637, 829, 627, 244, 284, 628, 604, 253, 638]}, {23: [324, 167, 488, 681, 487, 300, 687, 625, 436, 501, 438, 502, 821, 822, 635, 701, 414]}, {24: [352, 612, 390, 167, 297, 300, 251, 283, 625, 857, 635, 606]}, {25: [452, 390, 679, 743, 744, 685, 251, 470, 759, 761, 730, 699]}, {26: [324, 133, 805, 806, 360, 681, 422, 528, 535, 536, 857, 859, 798]}, {27: [800, 323, 324, 743, 744, 681, 829, 557, 687, 830, 315, 565, 759, 761, 730, 571, 316, 701, 606, 799]}, {28: [251, 390]}, {29: [768, 800, 612, 805, 806, 383, 606, 234, 814, 816, 849, 850, 799, 857, 604, 798, 767]}, {30: [609, 611, 292, 323, 324, 679, 649, 170, 829, 300, 685, 315, 699, 793, 794, 251, 316, 253, 830, 415]}, {31: [450, 610, 324, 805, 806, 839, 456, 329, 360, 635, 421, 422, 693, 284, 857, 537, 859, 604, 798, 799]}, {32: [544, 449, 451, 388, 455, 457, 330, 333, 853, 469, 249, 543]}, {33: [480, 707, 485, 486, 493, 499, 436, 438, 701, 479]}, {34: [390, 783, 784, 793, 794, 415, 292, 421, 679, 681, 170, 300, 685, 687, 307, 823, 824, 315, 828, 316, 829, 830, 699, 701, 323, 324, 849, 850, 727, 728, 857, 609, 611, 251]}, {35: [840, 330, 692, 693, 694]}, {36: [800, 797, 799]}, {37: [625, 635, 300, 167]}, {38: [450, 612, 391, 456, 392, 620, 814, 816, 849, 850, 564, 789, 790, 566, 857, 604, 606]}, {39: [800, 417, 641, 642, 631, 632, 783, 784, 658, 799, 629, 823, 824, 639]}, {40: [800, 609, 674, 611, 292, 486, 170, 300, 653, 654, 433, 434, 499, 500, 799, 312, 668, 415]}, {41: [450, 324, 421, 422, 391, 839, 329, 456, 392, 564, 693, 789, 790, 566, 635]}, {42: [390, 653, 543, 544, 421, 422, 297, 298, 557, 312, 324, 850, 727, 728, 729, 730, 741, 743, 635, 488, 487, 619, 620, 501, 502, 251]}, {43: [480, 641, 356, 292, 390, 168, 415, 170, 299, 300, 493, 494, 306, 632, 793, 794, 251, 479]}, {44: [450, 452, 615, 679, 297, 617, 685, 464, 850, 788, 821, 822, 470, 790, 249, 699, 413]}, {45: [800, 672, 674, 487, 488, 557, 501, 502]}, {46: [827, 324, 637, 390, 773, 681, 829, 687, 315, 628, 373, 380, 793, 794, 251, 828, 701, 638]}, {47: [549, 550, 455, 555, 556, 535, 536, 541, 542]}, {48: [649, 535, 536, 665, 541, 542, 549, 550, 555, 556, 307, 318, 705, 322, 455, 479, 480, 620, 493, 244, 253]}, {49: [649, 415, 292, 681, 682, 170, 300, 688, 691, 693, 702, 705, 451, 708, 325, 840, 457, 330, 846, 606, 479, 480, 609, 611, 493]}]\n"
     ]
    }
   ],
   "source": [
    "blocks_a_ids=[]\n",
    "blocks_b_ids=[]\n",
    "a_join_info=[]\n",
    "b_join_info=[]\n",
    "# how to get join attr range base on block id.\n",
    "for key,queries in enumerate(b_join_queries):\n",
    "    map_content={}\n",
    "    join_keys=[]\n",
    "    node_vals=[]\n",
    "    for query in queries:\n",
    "        join_keys+=pa_B.partition_tree.query_single_join(query)\n",
    "        node_vals+=pa_B.partition_tree.query_single(query)\n",
    "    map_content[key]=list(set(node_vals))\n",
    "    blocks_b_ids.append(map_content)\n",
    "\n",
    "    join_keys=list(set(join_keys))\n",
    "    join_info={\"nums\":len(join_keys),\"length\":[]}\n",
    "    for join_id in join_keys:\n",
    "        node=pa_B.partition_tree.nid_node_dict[join_id]\n",
    "        join_info[\"length\"].append(node.boundary[join_attr+node.num_dims]-node.boundary[join_attr])\n",
    "    b_join_info.append(join_info)\n",
    "\n",
    "for key in a_join_queries:\n",
    "    map_content={}\n",
    "    join_keys=[]\n",
    "    node_vals=[]\n",
    "    for query in a_join_queries[key]:\n",
    "        join_keys+=pa_A.partition_tree.query_single_join(query)\n",
    "        node_vals+=pa_A.partition_tree.query_single(query)\n",
    "    map_content[key]=list(set(node_vals))\n",
    "    blocks_a_ids.append(map_content)\n",
    "\n",
    "    join_keys=list(set(join_keys))\n",
    "    join_info={\"nums\":len(join_keys),\"length\":[]}\n",
    "    for join_id in join_keys:\n",
    "        node=pa_A.partition_tree.nid_node_dict[join_id]\n",
    "        join_info[\"length\"].append(node.boundary[join_attr+node.num_dims]-node.boundary[join_attr])\n",
    "    a_join_info.append(join_info)\n",
    "\n",
    "print(sum([len(group_ids[key]) for key,group_ids in enumerate(blocks_a_ids)]))\n",
    "print(sum([len(group_ids[key]) for key,group_ids in enumerate(blocks_b_ids)]))\n",
    "\n",
    "join_infos=[a_join_info,b_join_info]\n",
    "for join_info in join_infos:\n",
    "    total_nums,total_length=0,0\n",
    "    for item in join_info:\n",
    "        total_nums+=item['nums']\n",
    "        total_length+=sum(item['length'])\n",
    "    print(f\"{total_nums} , {round(total_length,2)}\")\n",
    "print(blocks_a_ids)\n",
    "print(blocks_b_ids)\n",
    "# print(a_join_info)\n",
    "# print(b_join_info)\n",
    "\n",
    "# -------------- for MyJoinTree----------\n",
    "# ------------case 1---------------------\n",
    "# block nums  A:57 B:81\n",
    "# join-parent-block nums  A:25 B:51\n",
    "# join-parent-block range length  A:1265005.98  B:2549584.81\n",
    "# ------------case 3---------------------\n",
    "# 305\n",
    "# 354\n",
    "# 139 , 6767143.1\n",
    "# 231 , 11477344.59\n",
    "\n",
    "# -------------- for AdaptJoinTree-------\n",
    "# ------------case 1---------------------\n",
    "# A:72 B:81\n",
    "# join-parent-block nums  A:30 B:51\n",
    "# join-parent-block range length  A:1499104.5  B:2549552.5\n",
    "# ------------case 3---------------------\n",
    "# 320\n",
    "# 386\n",
    "# 132 , 6599405.0\n",
    "# 244 , 12200356.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_intersection_size_count(setValues,listValues):\n",
    "    size=0\n",
    "    for lv in listValues:\n",
    "        if lv in setValues: size+=1\n",
    "    return size\n",
    "\n",
    "def get_intersection_detail(setValues,listValues):\n",
    "    size=0\n",
    "    intersection=[]\n",
    "    for lv in listValues:\n",
    "        if lv in setValues:\n",
    "            size+=1\n",
    "            intersection.append(lv)\n",
    "    return size,intersection\n",
    "\n",
    "def get_intersection_size(setValues,listValues):\n",
    "    size=0\n",
    "    for lv in listValues:\n",
    "        if lv in setValues: size+=pa_B.partition_tree.nid_node_dict[lv].node_size\n",
    "    return size\n",
    "\n",
    "def is_overlay(aid,bid):\n",
    "    bucket_a=pa_A.partition_tree.nid_node_dict[aid].boundary\n",
    "    bucket_b=pa_B.partition_tree.nid_node_dict[bid].boundary\n",
    "    return __overlap(bucket_a,bucket_b,join_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Use group algorithm to construct hyper environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this is the group algorithm in adaptDB paper\n",
    "def group1(overlap_chunks,join_a_block_ids,partition_size):\n",
    "    resizedSplits=[]\n",
    "    size=len(join_a_block_ids)\n",
    "    while size>0:\n",
    "        cur_splits=[]\n",
    "        chunks=[]\n",
    "        # max block size limit for every split.\n",
    "        splitAvailableSize = partition_size  # indicate the max B block in every partition, here B=2.\n",
    "        while size>0 and splitAvailableSize>0:\n",
    "            maxIntersection=-1\n",
    "            best_offset=-1\n",
    "            for offset,bid in enumerate(join_a_block_ids):\n",
    "                cur_intersection=get_intersection_size_count(chunks,overlap_chunks[bid])\n",
    "                if cur_intersection>maxIntersection:\n",
    "                    maxIntersection=cur_intersection\n",
    "                    best_offset=offset\n",
    "            bucket_id=join_a_block_ids[best_offset]\n",
    "            cur_splits.append(bucket_id)\n",
    "            chunks+=overlap_chunks[bucket_id]\n",
    "            chunks=list(set(chunks))\n",
    "            # for rhs in overlap_chunks[bucket_id]:\n",
    "            #     chunks.append(rhs)\n",
    "            join_a_block_ids.remove(bucket_id)\n",
    "            # splitAvailableSize-=pa_A.partition_tree.nid_node_dict[bucket_id].node_size\n",
    "            splitAvailableSize-=1\n",
    "            size-=1\n",
    "        resizedSplits.append(cur_splits)\n",
    "    return resizedSplits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# group2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# improve the original group algorithm, keep the time complex is O(n^2)\n",
    "def group2(overlap_chunks,join_a_block_ids,partition_size):\n",
    "    def list_solved_list(l1,l2):\n",
    "        for item1 in l1:\n",
    "            if item1 in l2:\n",
    "                return True\n",
    "        return False\n",
    "    resizedSplits=[]\n",
    "    size=len(join_a_block_ids)\n",
    "    # max block size limit for every split.\n",
    "    splitAvailableSize = partition_size  # indicate the max B block in every partition, here B=2.\n",
    "    affinity_tab=[]\n",
    "    pre_save_ids=[]\n",
    "    computed_ids_dict={}\n",
    "    time0=time.time()\n",
    "    for bid in join_a_block_ids: computed_ids_dict[tuple([bid])]={}\n",
    "    block_ids_length=len(join_a_block_ids)\n",
    "    for no1 in range(block_ids_length):\n",
    "        bid1=join_a_block_ids[no1]\n",
    "        for no2 in range(no1+1,block_ids_length):\n",
    "            bid2=join_a_block_ids[no2]\n",
    "            cur_intersection,its_content=get_intersection_detail(overlap_chunks[bid1],overlap_chunks[bid2])\n",
    "            computed_ids_dict[tuple([bid1])][tuple([bid2])]=[cur_intersection,its_content]\n",
    "            computed_ids_dict[tuple([bid2])][tuple([bid1])]=[cur_intersection,its_content]\n",
    "        computed_ids_dict[tuple([bid1])] = dict(sorted(computed_ids_dict[tuple([bid1])].items(), key=lambda k: k[1][0], reverse=True))\n",
    "        computed_ids_dict[tuple([bid1])][\"sorted_keys\"] = list(computed_ids_dict[tuple([bid1])].keys())\n",
    "        best_target_ids = computed_ids_dict[tuple([bid1])]['sorted_keys'][0]\n",
    "        max_intersection=computed_ids_dict[tuple([bid1])][best_target_ids][0]\n",
    "        if max_intersection==0:\n",
    "            pre_save_ids.append(bid1)\n",
    "        else:\n",
    "            max_bid=list(best_target_ids)\n",
    "            affinity_tab.append({'item':[[bid1],max_bid],'val':max_intersection})\n",
    "\n",
    "    # print(\"phase 1:\",time.time()-time0)\n",
    "    cur_index=0\n",
    "    # pre-save these ids which doesn't have any overlap blocks\n",
    "    while cur_index<len(pre_save_ids):\n",
    "        if cur_index+partition_size-1<=len(pre_save_ids)-1:\n",
    "            merge_ids=pre_save_ids[cur_index:cur_index+partition_size]\n",
    "        else:\n",
    "            merge_ids=pre_save_ids[cur_index:]\n",
    "        resizedSplits.append(merge_ids)\n",
    "        size-=len(merge_ids)\n",
    "        cur_index+=partition_size\n",
    "    phase2_time,phase3_time=0,0\n",
    "    while size>0:\n",
    "        time1 = time.time()\n",
    "        affinity_tab.sort(key=lambda item: (item['val'],len(item['item'][0])), reverse=True)\n",
    "        # print(f\"size: {size},   {affinity_tab}\")\n",
    "        sel_tab=affinity_tab.pop(0)\n",
    "        # note that: because may be len(sel_tab['item'][1])>1, so the length of merge_ids may be > splitAvailableSize\n",
    "        merge_ids=sel_tab['item'][0]+sel_tab['item'][1]\n",
    "        if sel_tab['val']!=-1:\n",
    "            # delete combined ids from computed_ids_dict\n",
    "            # computed_ids_dict.pop(tuple(sel_tab['item'][0]))\n",
    "            # computed_ids_dict.pop(tuple(sel_tab['item'][1]))\n",
    "            #update affinity_tab\n",
    "            for tab in reversed(affinity_tab):\n",
    "                # delete tab\n",
    "                if list_solved_list(tab['item'][0],sel_tab['item'][1]):\n",
    "                    affinity_tab.remove(tab)\n",
    "                    continue\n",
    "                # update tab\n",
    "                else:\n",
    "                    # delete the key which will be combined\n",
    "                    link_a_id=tuple(tab['item'][0])\n",
    "                    link_sort_keys=computed_ids_dict[link_a_id]['sorted_keys']\n",
    "                    item_list=[]\n",
    "                    is_top=False\n",
    "                    for sel_item in sel_tab['item']:\n",
    "                        target_a_id=tuple(sel_item)\n",
    "                        if target_a_id in link_sort_keys:\n",
    "                            if link_sort_keys.index(target_a_id)==0: is_top=True\n",
    "                            link_sort_keys.remove(target_a_id)\n",
    "                            item=computed_ids_dict[link_a_id].pop(target_a_id)\n",
    "                            item_list.append(item[1])\n",
    "                    if len(item_list)>=1:\n",
    "                        # if: the length of combined key is too long:\n",
    "                        min_allocate_length=splitAvailableSize-len(link_a_id)\n",
    "                        if len(merge_ids)<=min_allocate_length:\n",
    "                            # else: update the combined key\n",
    "                            new_item=[]\n",
    "                            for item in item_list: new_item+=item\n",
    "                            merged_items=list(set(new_item))\n",
    "                            merged_items_length=len(merged_items)\n",
    "                            for kid,key in enumerate(link_sort_keys):\n",
    "                                if merged_items_length>=computed_ids_dict[link_a_id][key][0]:\n",
    "                                    link_sort_keys.insert(kid,tuple(merge_ids))\n",
    "                                    break\n",
    "                            computed_ids_dict[link_a_id][tuple(merge_ids)]=[merged_items_length,merged_items]\n",
    "                    if is_top:\n",
    "                    # if list_solved_list(tab['item'][1],merge_ids):\n",
    "                        if len(link_sort_keys)==0:\n",
    "                            tab['item'][1]=[]\n",
    "                            tab['val'] =-1\n",
    "                        else:\n",
    "                            best_target_ids=link_sort_keys[0]\n",
    "                            tab['item'][1]=list(best_target_ids)\n",
    "                            tab['val']=computed_ids_dict[link_a_id][best_target_ids][0]\n",
    "            phase2_time+=time.time()-time1\n",
    "\n",
    "        if len(merge_ids)==splitAvailableSize or len(affinity_tab)==0 or sel_tab['val']==-1:\n",
    "            resizedSplits.append(merge_ids)\n",
    "            size-=len(merge_ids)\n",
    "        else:\n",
    "            time2 = time.time()\n",
    "            new_combined_tab={'item':[merge_ids,[]],'val':-1}\n",
    "            ud1_key=tuple(merge_ids)\n",
    "            # overlap_chunks1=[]\n",
    "            # for bid in ud1_key: overlap_chunks1+=overlap_chunks[bid]\n",
    "            # overlap_chunks1=list(set(overlap_chunks1))\n",
    "            min_allocate_length=splitAvailableSize-len(ud1_key)\n",
    "            # max_intersection=-1\n",
    "            # max_target_ids=[]\n",
    "            computed_ids_dict[ud1_key]={}\n",
    "            for ud_item2 in affinity_tab:\n",
    "                ud2_key=tuple(ud_item2['item'][0])\n",
    "                if len(ud2_key)>min_allocate_length: continue\n",
    "                # overlap_chunks2=[]\n",
    "                # for bid in ud2_key: overlap_chunks2+=overlap_chunks[bid]\n",
    "                # overlap_chunks2=list(set(overlap_chunks2))\n",
    "                # cur_intersection,its_content=get_intersection_detail(overlap_chunks1,overlap_chunks2)\n",
    "                # computed_ids_dict[ud1_key][ud2_key]=[cur_intersection,its_content]\n",
    "                # print(ud1_key,ud2_key)\n",
    "                # if ud1_key==tuple([536, 539, 289, 546, 767, 533, 549]):\n",
    "                #     print(1)\n",
    "                computed_ids_dict[ud1_key][ud2_key]=computed_ids_dict[ud2_key][ud1_key]\n",
    "                # if cur_intersection>max_intersection:\n",
    "                #     max_intersection=cur_intersection\n",
    "                #     max_target_ids=list(ud2_key)\n",
    "            computed_ids_dict[ud1_key]=dict(sorted(computed_ids_dict[ud1_key].items(), key=lambda k: k[1][0],reverse=True))\n",
    "            computed_ids_dict[ud1_key][\"sorted_keys\"]=list(computed_ids_dict[ud1_key].keys())\n",
    "            if len(computed_ids_dict[ud1_key][\"sorted_keys\"])>0:\n",
    "                best_target_ids = computed_ids_dict[ud1_key]['sorted_keys'][0]\n",
    "                new_combined_tab['item'][1] = list(best_target_ids)\n",
    "                new_combined_tab['val'] = computed_ids_dict[ud1_key][best_target_ids][0]\n",
    "            affinity_tab.append(new_combined_tab)\n",
    "            phase3_time += time.time() - time2\n",
    "        # Case: the affinity_tab only has one item.\n",
    "        # if len(affinity_tab)==1:\n",
    "        #     last_tab=affinity_tab.pop(0)\n",
    "        #     merge_ids=last_tab['item'][0]+last_tab['item'][1]\n",
    "        #     resizedSplits.append(merge_ids)\n",
    "        #     size-=len(merge_ids)\n",
    "    # print(\"phase 2:\", phase2_time)\n",
    "    # print(\"phase 3:\", phase3_time)\n",
    "    return resizedSplits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# group3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# best (group algorithm)\n",
    "def group3(overlap_chunks,join_a_block_ids,partition_size):\n",
    "    def list_solved_list(l1,l2):\n",
    "        for item1 in l1:\n",
    "            if item1 in l2:\n",
    "                return True\n",
    "        return False\n",
    "    resizedSplits=[]\n",
    "    size=len(join_a_block_ids)\n",
    "    # max block size limit for every split.\n",
    "    splitAvailableSize = partition_size  # indicate the max B block in every partition, here B=2.\n",
    "    affinity_tab=[]\n",
    "    pre_save_ids=[]\n",
    "    computed_ids_dict={}\n",
    "    for bid in join_a_block_ids: computed_ids_dict[bid]={}\n",
    "    a_block_len=len(join_a_block_ids)\n",
    "    for no1 in range(a_block_len):\n",
    "        bid1=join_a_block_ids[no1]\n",
    "        max_intersection=-1\n",
    "        max_bid=[]\n",
    "        for exist_bid in computed_ids_dict[bid1].keys():\n",
    "            cur_intersection=computed_ids_dict[bid1][exist_bid]\n",
    "            if cur_intersection>max_intersection:\n",
    "                max_intersection=cur_intersection\n",
    "                max_bid=[exist_bid]\n",
    "        for no2 in range(no1+1,a_block_len):\n",
    "            bid2=join_a_block_ids[no2]\n",
    "            cur_intersection=get_intersection_size_count(overlap_chunks[bid1],overlap_chunks[bid2])\n",
    "            computed_ids_dict[bid1][bid2]=cur_intersection\n",
    "            computed_ids_dict[bid2][bid1]=cur_intersection\n",
    "            if cur_intersection>max_intersection:\n",
    "                max_intersection=cur_intersection\n",
    "                max_bid=[bid2]\n",
    "        if max_intersection==0:\n",
    "            pre_save_ids.append(bid1)\n",
    "        else:\n",
    "            affinity_tab.append({'item':[[bid1],max_bid],'val':max_intersection,'chunk':overlap_chunks[bid1]})\n",
    "        #sort computed_ids_dict for bid1\n",
    "        # computed_ids_dict[bid1]=dict(sorted(computed_ids_dict[bid1].items(), key=lambda k: k[1],reverse=True))\n",
    "    # print(computed_ids_dict)\n",
    "    cur_index=0\n",
    "    # pre-save these ids which doesn't have any overlap blocks\n",
    "    while cur_index<len(pre_save_ids):\n",
    "        if cur_index+partition_size-1<=len(pre_save_ids)-1:\n",
    "            merge_ids=pre_save_ids[cur_index:cur_index+partition_size]\n",
    "        else:\n",
    "            merge_ids=pre_save_ids[cur_index:]\n",
    "        resizedSplits.append(merge_ids)\n",
    "        size-=len(merge_ids)\n",
    "        cur_index+=partition_size\n",
    "    while size>0:\n",
    "        affinity_tab.sort(key=lambda item: (item['val'],len(item['item'][0])), reverse=True)\n",
    "        # print(f\"size: {size},   {affinity_tab}\")\n",
    "        sel_tab=affinity_tab.pop(0)\n",
    "        # note that: because may be len(sel_tab['item'][1])>1, so the length of merge_ids may be > splitAvailableSize\n",
    "        merge_ids=sel_tab['item'][0]+sel_tab['item'][1]\n",
    "        merge_ids_length=len(merge_ids)\n",
    "        is_completed=False\n",
    "        if merge_ids_length==splitAvailableSize or len(affinity_tab)==0 or sel_tab['val']==-1:\n",
    "            is_completed=True\n",
    "            resizedSplits.append(merge_ids)\n",
    "            size-=merge_ids_length\n",
    "        else:\n",
    "            #add key=chunk\n",
    "            new_overlap_chunks=sel_tab['chunk']\n",
    "            for bid in sel_tab['item'][1]:\n",
    "                new_overlap_chunks+=overlap_chunks[bid]\n",
    "            new_tab={'item':[merge_ids,[]],'val':-1,'chunk':list(set(new_overlap_chunks))}\n",
    "\n",
    "        #update affinity_tab\n",
    "        for tab in reversed(affinity_tab):\n",
    "            # delete tab\n",
    "            if list_solved_list(tab['item'][0],sel_tab['item'][1]):\n",
    "                affinity_tab.remove(tab)\n",
    "                continue\n",
    "            # update tab\n",
    "            if list_solved_list(tab['item'][1],merge_ids):\n",
    "                if is_completed or len(tab['item'][0])+merge_ids_length>partition_size:\n",
    "                    tab['item'][1]=[]\n",
    "                    tab['val']=-1\n",
    "                else:\n",
    "                    tab['item'][1]=merge_ids\n",
    "                    tab['val']=get_intersection_size_count(tab['chunk'],new_tab['chunk'])\n",
    "        if not is_completed:affinity_tab.append(new_tab)\n",
    "        # Case: the affinity_tab only has one item.\n",
    "        if len(affinity_tab)==1:\n",
    "            last_tab=affinity_tab.pop(0)\n",
    "            merge_ids=last_tab['item'][0]+last_tab['item'][1]\n",
    "            resizedSplits.append(merge_ids)\n",
    "            size-=len(merge_ids)\n",
    "        # new round: these ids need to be updated\n",
    "        for ud_item1 in affinity_tab:\n",
    "            if ud_item1['val']==-1:\n",
    "                ud1_key=ud_item1['item'][0]\n",
    "                flag1=False\n",
    "                if len(ud1_key)==1: flag1=True\n",
    "                # if flag1:\n",
    "                #     single_target_ids=[next(iter(computed_ids_dict[ud1_key[0]]))]\n",
    "                #     single_max_intersection=computed_ids_dict[ud1_key[0]][single_target_ids[0]]\n",
    "                    # print(f\"{single_target_ids} --- {single_max_intersection}\")\n",
    "                # overlap_chunks1=[]\n",
    "                # for bid in ud1_key: overlap_chunks1+=overlap_chunks[bid]\n",
    "                # overlap_chunks1=list(set(overlap_chunks1))\n",
    "\n",
    "                # if flag1:\n",
    "                #     overlap_chunks1=overlap_chunks[ud1_key[0]]\n",
    "                # else:\n",
    "                overlap_chunks1=ud_item1['chunk']\n",
    "                min_allocate_length=splitAvailableSize-len(ud1_key)\n",
    "                max_intersection=-1\n",
    "                max_target_ids=[]\n",
    "                for ud_item2 in affinity_tab:\n",
    "                    ud2_key=ud_item2['item'][0]\n",
    "                    if ud1_key==ud2_key:continue\n",
    "                    if len(ud2_key)>min_allocate_length: continue\n",
    "                    if ud_item2['item'][1]==ud1_key:\n",
    "                        cur_intersection=ud_item2['val']\n",
    "                    else:\n",
    "                        # if flag1 and len(ud2_key)==1:continue\n",
    "                        flag2=False\n",
    "                        if len(ud2_key)==1: flag2=True\n",
    "                        if flag1 and flag2:\n",
    "                            cur_intersection=computed_ids_dict[ud1_key[0]][ud2_key[0]]\n",
    "                        else:\n",
    "                            overlap_chunks2=ud_item2['chunk']\n",
    "                            # overlap_chunks2=[]\n",
    "                            # for bid in ud2_key: overlap_chunks2+=overlap_chunks[bid]\n",
    "                            # overlap_chunks2=list(set(overlap_chunks2))\n",
    "                            cur_intersection=get_intersection_size_count(overlap_chunks1,overlap_chunks2)\n",
    "                    if cur_intersection>max_intersection:\n",
    "                        max_intersection=cur_intersection\n",
    "                        max_target_ids=ud2_key\n",
    "                # if flag1:\n",
    "                #     if single_max_intersection>max_intersection:\n",
    "                #         max_intersection=single_max_intersection\n",
    "                #         max_target_ids=single_target_ids\n",
    "                ud_item1['val']=max_intersection\n",
    "                ud_item1['item'][1]=max_target_ids\n",
    "    return resizedSplits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# group4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# improve the original group algorithm\n",
    "def group4(overlap_chunks,join_a_block_ids,partition_size):\n",
    "    def list_solved_list(l1,l2):\n",
    "        for item1 in l1:\n",
    "            if item1 in l2:\n",
    "                return True\n",
    "        return False\n",
    "    resizedSplits=[]\n",
    "    size=len(join_a_block_ids)\n",
    "    # max block size limit for every split.\n",
    "    splitAvailableSize = partition_size  # indicate the max B block in every partition, here B=2.\n",
    "    affinity_tab=[]\n",
    "    pre_save_ids=[]\n",
    "    computed_ids_dict={}\n",
    "    for bid1 in join_a_block_ids:\n",
    "        max_intersection=-1\n",
    "        max_bid=[]\n",
    "        computed_ids_dict[bid1]={}\n",
    "        for bid2 in join_a_block_ids:\n",
    "            if bid1==bid2:continue\n",
    "            cur_intersection=get_intersection_size_count(overlap_chunks[bid1],overlap_chunks[bid2])\n",
    "            computed_ids_dict[bid1][bid2]=cur_intersection\n",
    "            if cur_intersection>max_intersection:\n",
    "                max_intersection=cur_intersection\n",
    "                max_bid=[bid2]\n",
    "        if max_intersection==0:\n",
    "            pre_save_ids.append(bid1)\n",
    "        else:\n",
    "            affinity_tab.append({'item':[[bid1],max_bid],'val':max_intersection,'chunk':overlap_chunks[bid1]})\n",
    "        #sort computed_ids_dict for bid1\n",
    "        # computed_ids_dict[bid1]=dict(sorted(computed_ids_dict[bid1].items(), key=lambda k: k[1],reverse=True))\n",
    "    # print(computed_ids_dict)\n",
    "    cur_index=0\n",
    "    # pre-save these ids which doesn't have any overlap blocks\n",
    "    while cur_index<len(pre_save_ids):\n",
    "        if cur_index+partition_size-1<=len(pre_save_ids)-1:\n",
    "            merge_ids=pre_save_ids[cur_index:cur_index+partition_size]\n",
    "        else:\n",
    "            merge_ids=pre_save_ids[cur_index:]\n",
    "        resizedSplits.append(merge_ids)\n",
    "        size-=len(merge_ids)\n",
    "        cur_index+=partition_size\n",
    "    while size>0:\n",
    "        affinity_tab.sort(key=lambda item: (item['val'],len(item['item'][0])), reverse=True)\n",
    "        # print(f\"size: {size},   {affinity_tab}\")\n",
    "        sel_tab=affinity_tab.pop(0)\n",
    "        # note that: because may be len(sel_tab['item'][1])>1, so the length of merge_ids may be > splitAvailableSize\n",
    "        merge_ids=sel_tab['item'][0]+sel_tab['item'][1]\n",
    "        #update affinity_tab\n",
    "        for tab in reversed(affinity_tab):\n",
    "            # delete tab\n",
    "            if list_solved_list(tab['item'][0],sel_tab['item'][1]):\n",
    "                affinity_tab.remove(tab)\n",
    "                continue\n",
    "            # update tab\n",
    "            if list_solved_list(tab['item'][1],merge_ids):\n",
    "                # if len(tab['item'][0])==1 and len(tab['item'][1])==1:\n",
    "                    # print(f\"{tab['item'][0][0]} {tab['item'][1][0]}=>{computed_ids_dict[tab['item'][0][0]][tab['item'][1][0]]} is removed!!!!\")\n",
    "                    # computed_ids_dict[tab['item'][0][0]].pop(tab['item'][1][0])\n",
    "                tab['item'][1]=[]\n",
    "                tab['val']=-1\n",
    "\n",
    "        if len(merge_ids)==splitAvailableSize or len(affinity_tab)==0 or sel_tab['val']==-1:\n",
    "            resizedSplits.append(merge_ids)\n",
    "            size-=len(merge_ids)\n",
    "        else:\n",
    "            #add key=chunk\n",
    "            new_overlap_chunks=sel_tab['chunk']\n",
    "            for bid in sel_tab['item'][1]:\n",
    "                new_overlap_chunks+=overlap_chunks[bid]\n",
    "            affinity_tab.append({'item':[merge_ids,[]],'val':-1,'chunk':list(set(new_overlap_chunks))})\n",
    "        # Case: the affinity_tab only has one item.\n",
    "        if len(affinity_tab)==1:\n",
    "            last_tab=affinity_tab.pop(0)\n",
    "            merge_ids=last_tab['item'][0]+last_tab['item'][1]\n",
    "            resizedSplits.append(merge_ids)\n",
    "            size-=len(merge_ids)\n",
    "        # new round: these ids need to be updated\n",
    "        for ud_item1 in affinity_tab:\n",
    "            if ud_item1['val']==-1:\n",
    "                ud1_key=ud_item1['item'][0]\n",
    "                flag1=False\n",
    "                if len(ud1_key)==1: flag1=True\n",
    "                # if flag1:\n",
    "                #     single_target_ids=[next(iter(computed_ids_dict[ud1_key[0]]))]\n",
    "                #     single_max_intersection=computed_ids_dict[ud1_key[0]][single_target_ids[0]]\n",
    "                    # print(f\"{single_target_ids} --- {single_max_intersection}\")\n",
    "                # overlap_chunks1=[]\n",
    "                # for bid in ud1_key: overlap_chunks1+=overlap_chunks[bid]\n",
    "                # overlap_chunks1=list(set(overlap_chunks1))\n",
    "\n",
    "                # if flag1:\n",
    "                #     overlap_chunks1=overlap_chunks[ud1_key[0]]\n",
    "                # else:\n",
    "                overlap_chunks1=ud_item1['chunk']\n",
    "                min_allocate_length=splitAvailableSize-len(ud1_key)\n",
    "                max_intersection=-1\n",
    "                max_target_ids=[]\n",
    "                for ud_item2 in affinity_tab:\n",
    "                    ud2_key=ud_item2['item'][0]\n",
    "                    if ud1_key==ud2_key:continue\n",
    "                    if len(ud2_key)>min_allocate_length: continue\n",
    "                    # if flag1 and len(ud2_key)==1:continue\n",
    "                    flag2=False\n",
    "                    if len(ud2_key)==1: flag2=True\n",
    "                    if flag1 and flag2:\n",
    "                        cur_intersection=computed_ids_dict[ud1_key[0]][ud2_key[0]]\n",
    "                    else:\n",
    "                        overlap_chunks2=ud_item2['chunk']\n",
    "                        # overlap_chunks2=[]\n",
    "                        # for bid in ud2_key: overlap_chunks2+=overlap_chunks[bid]\n",
    "                        # overlap_chunks2=list(set(overlap_chunks2))\n",
    "                        cur_intersection=get_intersection_size_count(overlap_chunks1,overlap_chunks2)\n",
    "                    if cur_intersection>max_intersection:\n",
    "                        max_intersection=cur_intersection\n",
    "                        max_target_ids=ud2_key\n",
    "                # if flag1:\n",
    "                #     if single_max_intersection>max_intersection:\n",
    "                #         max_intersection=single_max_intersection\n",
    "                #         max_target_ids=single_target_ids\n",
    "                ud_item1['val']=max_intersection\n",
    "                ud_item1['item'][1]=max_target_ids\n",
    "    return resizedSplits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Use group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_group(group_no,partition_size):\n",
    "    #compute hyper join cost\n",
    "    final_resized_splits=[]\n",
    "    overlap_chunks_for_queries=[]\n",
    "    intersection_reward=0\n",
    "    total_hyper_cost=0\n",
    "    build_time=0\n",
    "    for idx in range(len(blocks_a_ids)):\n",
    "        # if idx<=2:continue\n",
    "        join_a_block_ids=[]\n",
    "        for key in blocks_a_ids[idx].keys():\n",
    "            join_a_block_ids+=blocks_a_ids[idx][key]\n",
    "\n",
    "        join_b_block_ids=[]\n",
    "        for key in blocks_b_ids[idx].keys():\n",
    "            join_b_block_ids+=blocks_b_ids[idx][key]\n",
    "        # group algorithm\n",
    "        #step1: generate overlap_chunks\n",
    "        overlap_chunks={}\n",
    "        for aid in join_a_block_ids:\n",
    "            if aid not in overlap_chunks.keys(): overlap_chunks[aid]=[]\n",
    "            for bid in join_b_block_ids:\n",
    "                if is_overlay(aid,bid): overlap_chunks[aid].append(bid)\n",
    "        # print(f\"overlap chunks: \",overlap_chunks)\n",
    "        overlap_chunks_for_queries.append(overlap_chunks)\n",
    "        # step2: group\n",
    "        # print(overlap_chunks)\n",
    "        # print(join_a_block_ids)\n",
    "        time0=time.time()\n",
    "        if group_no==1: resizedSplits=group1(overlap_chunks,join_a_block_ids,partition_size)\n",
    "        elif group_no==3: resizedSplits=group3(overlap_chunks,join_a_block_ids,partition_size)\n",
    "        build_time+=time.time()-time0\n",
    "        for group in resizedSplits:\n",
    "            all_b_ids=[]\n",
    "            for a_id in group:\n",
    "                all_b_ids+=overlap_chunks[a_id]\n",
    "                # print(overlap_chunks[a_id])\n",
    "            actual_b_ids=list(set(all_b_ids))\n",
    "            intersection_reward+=len(all_b_ids)-len(actual_b_ids)\n",
    "            total_hyper_cost+=sum([pa_B.partition_tree.nid_node_dict[_].node_size for _ in actual_b_ids])\n",
    "#         print(f\"join-query#{idx}: {resizedSplits}\")\n",
    "        final_resized_splits.append(resizedSplits)\n",
    "#     print(\"intersection_reward: \",intersection_reward)\n",
    "#     print(\"total_hyper_cost: \",total_hyper_cost)\n",
    "#     print(\"average build time: \", build_time/len(blocks_a_ids))\n",
    "    return total_hyper_cost,build_time/len(blocks_a_ids)\n",
    "# group2 / group3\n",
    "# intersection_reward | total_hyper_cost | partition size\n",
    "# 288|340701|2   407|260066|3  428|246400|4   6692|1744131|4  6779|856091|8 0.00672974 / 0.00371\n",
    "# 7186|908487|0.00336  9556|1052549|0.00313  8898|902875|0.00309\n",
    "# group1\n",
    "# 277|348366|2   402|263348|3  424|248776|4   6459|1901532|4  6643 943140 0.000183264\n",
    "# 7060|989574|0.000226  7999|1139279|0.0002524  7457|990121|0.000220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the hyper cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: [[24912426, 21185037], [0.0005584096908569336, 0.002687816619873047]], 8: [[15069076, 12154032], [0.0004893875122070312, 0.0024381113052368165]], 16: [[9041161, 7909420], [0.0005063676834106446, 0.002410430908203125]]}\n"
     ]
    }
   ],
   "source": [
    "size_list=[4,8,16]\n",
    "g_nos=[1,3]\n",
    "result_dict={}\n",
    "for partition_size in size_list:\n",
    "    res_cost=[]\n",
    "    res_time=[]\n",
    "    for g_no in g_nos:\n",
    "        hyper_cost,avg_build_time=run_group(g_no,partition_size)\n",
    "        res_cost.append(hyper_cost)\n",
    "        res_time.append(avg_build_time)\n",
    "    result_dict[partition_size]=[res_cost,res_time]\n",
    "print(result_dict)\n",
    "\n",
    "# used_dims=[1,2,4]\n",
    "# 500,300 depth=3\n",
    "# {4: [[32524778, 28226328], [0.0010062503814697267, 0.006084232330322265]], \n",
    "# 8: [[17664703, 15555503], [0.0007469940185546875, 0.004853806495666504]], \n",
    "# 16: [[9975904, 9237027], [0.00076019287109375, 0.004315085411071777]]}\n",
    "\n",
    "# 500,300 depth=4\n",
    "# {4: [[25188721, 21039709], [0.0005351400375366211, 0.0033372354507446287]],\n",
    "#  8: [[13654198, 12081376], [0.0005328512191772461, 0.0030576610565185547]], \n",
    "#  16: [[8543334, 7450621], [0.0005544233322143555, 0.0028368043899536133]]}\n",
    "\n",
    "# 300,200 depth=4\n",
    "# {4: [[21683817, 18546698], [0.0004356145858764648, 0.0021953344345092773]], \n",
    "#  8: [[13003233, 10743871], [0.00041507244110107423, 0.0020711040496826172]], \n",
    "#  16: [[8028951, 7020171], [0.0004153299331665039, 0.00202239990234375]]}\n",
    "\n",
    "# 200,150 depth=4\n",
    "# {4: [[17333986, 15034905], [0.0003401803970336914, 0.0018434667587280274]], \n",
    "#  8: [[10927518, 9402758], [0.0003495502471923828, 0.0013416099548339843]], \n",
    "#  16: [[7308485, 6515175], [0.00027172088623046877, 0.0013067388534545898]]}\n",
    "\n",
    "\n",
    "# used_dims=[1,2]\n",
    "# 300,200 depth=4\n",
    "# {4: [[27021260, 23302971], [0.0004562997817993164, 0.002252936363220215]], \n",
    "#  8: [[16188900, 13725843], [0.0004726505279541016, 0.0022165775299072266]], \n",
    "#  16: [[10898589, 9203511], [0.0004589557647705078, 0.002165408134460449]]}\n",
    "\n",
    "# used_dims=[1,2,4]\n",
    "# 300,200 depth=4\n",
    "# {4: [[24912426, 21185037], [0.0005584096908569336, 0.002687816619873047]], \n",
    "#  8: [[15069076, 12154032], [0.0004893875122070312, 0.0024381113052368165]], \n",
    "#  16: [[9041161, 7909420], [0.0005063676834106446, 0.002410430908203125]]}\n",
    "\n",
    "\n",
    "# used_dims=[1,2,4,5]\n",
    "# 300,200 depth=4\n",
    "# {4: [[12408833, 10302176], [0.00021513938903808594, 0.001195211410522461]], \n",
    "#  8: [[7269179, 6169309], [0.00021058082580566406, 0.0011177873611450196]], \n",
    "#  16: [[4587706, 4166675], [0.00021451473236083985, 0.0011197137832641602]]}\n",
    "\n",
    "# used_dims=[1,2,4,5,6]\n",
    "# {4: [[11497252, 9953197], [0.00021691322326660155, 0.001299896240234375]], \n",
    "#  8: [[6547248, 5785032], [0.0001961803436279297, 0.0010801458358764649]], \n",
    "#  16: [[4298119, 3853321], [0.00018740177154541015, 0.0010425615310668945]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 5.5  final revised version\n",
    "\n",
    "#-----------group1--------------\n",
    "# intersection_reward:  6702\n",
    "# total_hyper_cost:  930903\n",
    "# average build time:  0.00024812936782836914\n",
    "#\n",
    "\n",
    "#-----------group3 best--------------\n",
    "# intersection_reward:  8018\n",
    "# total_hyper_cost:  857326\n",
    "# average build time:  0.0013258218765258788\n",
    "\n",
    "#-----------group4--------------\n",
    "# intersection_reward:  7986\n",
    "# total_hyper_cost:  857326\n",
    "# average build time:  0.0032418872833251954\n",
    "\n",
    "#-----------group1--------------\n",
    "# intersection_reward:  5623\n",
    "# total_hyper_cost:  1478181\n",
    "# average build time:  0.0009099197387695313\n",
    "\n",
    "#-----------group3 best--------------\n",
    "# intersection_reward:  6847\n",
    "# total_hyper_cost:  1278114\n",
    "# average build time:  0.004601197242736816\n",
    "\n",
    "#-----------group4--------------\n",
    "# intersection_reward:  6823\n",
    "# total_hyper_cost:  1288218\n",
    "# average build time:  0.011755657196044923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_resized_splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-c590a20f8c01>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mtotal_reference_block_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mshuffle_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mq_no\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mresizedSplits\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfinal_resized_splits\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0mcnt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mtotal_b_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'final_resized_splits' is not defined"
     ]
    }
   ],
   "source": [
    "total_hyper_read_cost = 0  #the dataset size loaded in memory\n",
    "total_hyper_block_num=0\n",
    "total_shuffle_read_cost = 0\n",
    "total_reference_block_size = 0\n",
    "shuffle_weight=3\n",
    "for q_no,resizedSplits in enumerate(final_resized_splits):\n",
    "    cnt = 0\n",
    "    total_b_ids = []\n",
    "    total_a_ids=[]\n",
    "    overlap_chunks=overlap_chunks_for_queries[q_no]\n",
    "    for group in resizedSplits:\n",
    "        b_ids = []\n",
    "        for a_id in group:\n",
    "            total_reference_block_size += pa_A.partition_tree.nid_node_dict[a_id].node_size\n",
    "            b_ids += overlap_chunks[a_id]\n",
    "            total_a_ids.append(a_id)\n",
    "            cnt += 1\n",
    "        b_ids = list(set(b_ids))\n",
    "        total_b_ids += b_ids\n",
    "        total_hyper_block_num+=len(b_ids)\n",
    "        for b_id in b_ids:\n",
    "            total_hyper_read_cost += pa_B.partition_tree.nid_node_dict[b_id].node_size\n",
    "    total_b_ids = list(set(total_b_ids))\n",
    "    for b_id in total_b_ids:\n",
    "        total_shuffle_read_cost += shuffle_weight * pa_B.partition_tree.nid_node_dict[b_id].node_size\n",
    "    for a_id in total_a_ids:\n",
    "        total_shuffle_read_cost+=shuffle_weight*pa_A.partition_tree.nid_node_dict[a_id].node_size\n",
    "        total_hyper_read_cost+=pa_A.partition_tree.nid_node_dict[a_id].node_size\n",
    "print('total_hyper_read_cost:', total_hyper_read_cost)\n",
    "print('total_shuffle_read_cost:', total_shuffle_read_cost)\n",
    "print('total_reference_block_size:', total_reference_block_size)\n",
    "print('total_hyper_block_num:', total_hyper_block_num)\n",
    "\n",
    "# Join plan: based on skip\n",
    "# -------------------case1------------\n",
    "# total_hyper_read_cost: 78698\n",
    "# total_shuffle_read_cost: 199746\n",
    "# total_reference_block_size: 41194\n",
    "# -------------------case2------------\n",
    "# total_hyper_read_cost: 82551\n",
    "# total_shuffle_read_cost: 199233\n",
    "# total_reference_block_size: 39316\n",
    "# -------------------case2 part-qdtree------------\n",
    "# the result is same, may be these join queries always locate some blocks which can adapt them\n",
    "# no effect\n",
    "# -------------------case3------------\n",
    "# total_hyper_read_cost: 1149406\n",
    "# total_shuffle_read_cost: 2975163\n",
    "# total_reference_block_size: 192263\n",
    "# -------------------case4+group3------------\n",
    "# total_hyper_read_cost: 4341846\n",
    "# total_shuffle_read_cost: 11358102\n",
    "# total_reference_block_size: 3438971\n",
    "# total_hyper_block_num: 1413\n",
    "\n",
    "\n",
    "# Join plan: based on median value\n",
    "# -------------------case1------------\n",
    "# total_hyper_read_cost: 110670\n",
    "# total_shuffle_read_cost: 285937\n",
    "# total_reference_block_size: 42777\n",
    "# -------------------case2------------\n",
    "# total_hyper_read_cost: 146764\n",
    "# total_shuffle_read_cost: 383776\n",
    "# total_reference_block_size: 49158\n",
    "# -------------------case2 part-qdtree------------\n",
    "# no effect\n",
    "# -------------------case3------------\n",
    "# total_hyper_read_cost: 1379277\n",
    "# total_shuffle_read_cost: 3604218\n",
    "# total_reference_block_size: 222051\n",
    "# -------------------case4+group1------------\n",
    "# total_hyper_read_cost: 4827610\n",
    "# total_shuffle_read_cost: 12037191\n",
    "# total_reference_block_size: 3608128\n",
    "# total_hyper_block_num: 1886"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}